---
title: "Resumen Bayes"
output: html_document
date: "2024-05-05"
---
Por supuesto, aquí tienes una lista completa de distribuciones continuas y discretas con ejemplos de su posible uso y para qué fenómenos se utilizan:

**Distribuciones Continuas:**

1. **Distribución Normal (Gaussiana)**:
   - **Uso**: Modela variables continuas que tienden a agruparse alrededor de un valor central. Es muy utilizada debido al teorema del límite central y su relación con el error aleatorio en muchas medidas.
   - **Ejemplo**: Puede usarse para modelar la altura de una población, donde la mayoría de las personas tienen una altura cercana a la media, con pocas personas muy altas o muy bajas.

2. **Distribución Exponencial**:
   - **Uso**: Modela el tiempo entre eventos sucesivos en un proceso de Poisson, es decir, eventos que ocurren de manera continua e independiente en el tiempo. Es útil para modelar eventos que ocurren aleatoriamente con una tasa constante.
   - **Ejemplo**: Se utiliza para modelar el tiempo entre llegadas de clientes a un mostrador de servicio.

3. **Distribución Uniforme**:
   - **Uso**: Modela una variable continua donde cada valor dentro de un rango dado es igualmente probable.
   - **Ejemplo**: Se usa en problemas donde todas las posibilidades dentro de un rango tienen la misma probabilidad de ocurrencia, como el lanzamiento de un dado no sesgado.

4. **Distribución Gamma**:
   - **Uso**: Modela tiempos de espera, procesos de desgaste o tasas de eventos en el tiempo.
   - **Ejemplo**: Se utiliza en la industria para modelar tiempos de espera, como el tiempo entre fallos de un sistema.

5. **Distribución de Chi-cuadrado**:
   - **Uso**: Modela la distribución de la suma de los cuadrados de variables aleatorias normales estándar independientes. Es útil en pruebas de hipótesis y en la construcción de intervalos de confianza para la varianza de una población normal.
   - **Ejemplo**: Se usa en análisis de varianza (ANOVA) para probar si hay diferencias significativas entre las medias de varios grupos.

6. **Distribución t de Student**:
   - **Uso**: Se utiliza para estimar la media de una población cuando el tamaño de la muestra es pequeño y/o la desviación estándar de la población es desconocida. También se utiliza en pruebas de hipótesis sobre la media de una población.
   - **Ejemplo**: Se utiliza en pruebas t para comparar las medias de dos grupos de datos independientes.

7. **Distribución F de Fisher-Snedecor**:
   - **Uso**: Modela la relación entre dos varianzas muestrales y se utiliza en análisis de varianza (ANOVA) y en pruebas de regresión.
   - **Ejemplo**: Se utiliza en análisis de regresión para probar si el modelo de regresión es significativo.

**Distribuciones Discretas:**

1. **Distribución de Poisson**:
   - **Uso**: Modela la cantidad de eventos que ocurren en un intervalo de tiempo o espacio, cuando los eventos ocurren de manera independiente y a una tasa constante.
   - **Ejemplo**: Se utiliza para modelar el número de llamadas recibidas por un centro de atención telefónica en un intervalo de tiempo fijo, como por ejemplo, el número de llamadas por hora.

2. **Distribución Binomial**:
   - **Uso**: Modela el número de éxitos en una secuencia de ensayos independientes, donde cada ensayo tiene solo dos posibles resultados (éxito o fracaso).
   - **Ejemplo**: Se utiliza para modelar el número de veces que una moneda sale cara en un cierto número de lanzamientos, o el número de clientes que compran un producto de dos opciones en un día de ventas.

3. **Distribución de Bernoulli**:
   - **Uso**: Es un caso especial de la distribución binomial donde solo hay un ensayo. Modela un ensayo con dos resultados posibles (éxito o fracaso) con una probabilidad fija.
   - **Ejemplo**: Puede utilizarse para modelar el resultado de un solo lanzamiento de una moneda, donde el éxito sería obtener cara y el fracaso sería obtener cruz.

4. **Distribución Geométrica**:
   - **Uso**: Modela el número de ensayos independientes necesarios hasta que ocurra el primer éxito en una secuencia de ensayos de Bernoulli.
   - **Ejemplo**: Puede usarse para modelar el número de veces que se debe lanzar una moneda hasta que salga cara por primera vez.

5. **Distribución Hipergeométrica**:
   - **Uso**: Modela el número de éxitos en una muestra aleatoria sin reemplazo, donde cada ensayo tiene dos posibles resultados y el número total de éxitos y fracasos en la población es finito.
   - **Ejemplo**: Se utiliza para modelar el número de elementos defectuosos en una muestra aleatoria extraída de un lote de productos.

6. **Distribución Multinomial**:
   - **Uso**: Es una generalización de la distribución binomial para múltiples categorías. Modela el número de veces que ocurre cada una de varias categorías en una serie de ensayos independientes.
   - **Ejemplo**: Se utiliza en genética para modelar la distribución de genotipos en una población, donde hay más de dos posibles genotipos.

7. **Distribución de Poisson Multivariada**:
   - **Uso**: Extiende la distribución de Poisson a múltiples variables aleatorias, donde cada una representa el número de eventos en una región específica o en un intervalo de tiempo.
   - **Ejemplo**: Se utiliza en estudios epidemiológicos para modelar el número de casos de enfermedades infecciosas en diferentes regiones geográficas durante un período de tiempo.
  
  
Suponga que tiene que explicar a un estadístico frecuentista el papel de la probabilidad predictiva posterior en el pensamiento bayesiano y las ventajas que este concepto ofrece. Desarrolle tres ideas para lograr con éxito su explicación.

**Actualización continua de creencias:**
La probabilidad predictiva posterior en el pensamiento bayesiano representa la incertidumbre sobre eventos futuros después de observar los datos.
Proporciona una distribución completa que refleja esta incertidumbre, en contraste con estimaciones puntuales frecuentistas.
**Evaluación completa de la incertidumbre:**
Permite evaluar toda la distribución posterior, ofreciendo una visión completa de la incertidumbre asociada con las predicciones.
**Flexibilidad para incorporar nueva información:**
Se actualiza fácilmente con nuevos datos, permitiendo una adaptación continua y mejoras en las predicciones sin necesidad de reiniciar el análisis desde cero.


Suponga que tiene que explicar a un estadístico frecuentista el papel de la probabilidad predictiva previa en el pensamiento bayesiano y las ventajas que este concepto ofrece. Desarrolle tres ideas para lograr con éxito su explicación.

**Consideración de incertidumbre previa:**
La probabilidad predictiva previa en el pensamiento bayesiano cuantifica la incertidumbre previa sobre eventos futuros antes de observar nuevos datos.
**Mejora de la toma de decisiones:**
Permite decisiones más informadas, integrando información previa y nueva de manera sistemática, especialmente en situaciones de datos limitados.
**Flexibilidad y adaptabilidad**:
Ofrece flexibilidad para expresar y actualizar creencias iniciales a medida que se obtiene nueva información, en contraste con supuestos rígidos frecuentistas sobre la distribución de datos.

Suponga que tiene que explicar a un estadístico frecuentista el papel de la verosimilitud en el pensamiento bayesiano y las ventajas que este concepto ofrece. Desarrolle tres ideas para lograr con éxito su explicación.

**Medición de la compatibilidad de los datos:** La verosimilitud en el pensamiento bayesiano mide qué tan probable son los datos observados bajo diferentes valores del parámetro, lo que facilita la evaluación de la plausibilidad de esos valores.
**Integración de información previa y actualizada:** La verosimilitud se combina con la distribución a priori para calcular la distribución posterior, permitiendo una actualización coherente de nuestras creencias sobre el parámetro después de observar los datos.
**Flexibilidad y comparación de modelos:** La verosimilitud proporciona flexibilidad para abordar diferentes tipos de modelos y permite la comparación formal entre ellos, facilitando la selección del modelo más adecuado y la obtención de conclusiones más informadas.

Suponga que tiene que explicar a un estadístico frecuentista el papel de la distribución posterior en el pensamiento bayesiano y las ventajas que este concepto ofrece. Desarrolle tres ideas para lograr con éxito su explicación.

**Actualización de creencias:** La distribución posterior en el pensamiento bayesiano representa la actualización de nuestras creencias sobre un parámetro después de observar datos. Esto permite incorporar la incertidumbre de manera intuitiva y continua en el análisis estadístico.
**Fusión de información:** La distribución posterior integra de manera coherente la información previa con la evidencia empírica, ofreciendo una forma sistemática de combinar conocimientos previos con nuevos datos.
**Inferencia robusta y flexible:** La distribución posterior proporciona herramientas para realizar inferencias robustas y flexibles, incluyendo estimaciones puntuales, intervalos de credibilidad y comparaciones formales entre modelos, lo que permite abordar una variedad de preguntas de interés práctico de manera transparente.

Suponga que tiene que explicar a un estadístico frecuentista el papel de la distribución previa en el pensamiento bayesiano y las ventajas que este concepto ofrece. Desarrolle tres ideas para lograr con éxito su explicación.

**Incorporación de conocimiento previo:** La distribución previa en el pensamiento bayesiano permite utilizar información previa sobre los parámetros del modelo antes de observar los datos, lo que es útil cuando se dispone de conocimiento experto o creencias sólidas sobre el problema.
**Regularización y manejo de datos escasos:** La distribución previa actúa como un regularizador, suavizando las estimaciones de los parámetros y evitando problemas de sobreajuste, especialmente en situaciones con datos limitados o modelos complejos.
**Actualización continua de creencias:** El enfoque bayesiano permite actualizar continuamente las creencias a medida que se observan más datos, proporcionando una toma de decisiones más dinámica y adaptable en comparación con los enfoques frecuentistas, que a menudo generan estimaciones puntuales sin incorporar nuevas evidencias de manera sistemática.


**Partes de un modelo bayesiano**

**Distribución Previa:** Es la creencia inicial sobre los parámetros de un modelo estadístico antes de observar los datos. Enfoques frecuentistas tienden a verla como una distribución hipotética o una suposición inicial basada en el conocimiento previo del estadístico sobre el problema. Por ejemplo, si estás modelando la tasa de éxito de un tratamiento médico, la distribución previa podría representar tu creencia inicial sobre cuál podría ser esa tasa de éxito basada en estudios previos o experiencia clínica.

**Verosimilitud:** Es la probabilidad de observar los datos dados los parámetros del modelo. Enfoques frecuentistas la interpretan como una función de los datos, tratándola como una medida de la calidad del ajuste entre los datos observados y los parámetros propuestos. Por ejemplo, si estás evaluando un modelo de regresión lineal, la verosimilitud cuantifica qué tan probable son los datos observados bajo el modelo de regresión específico.

**Distribución Posterior:** Es la actualización de la distribución previa después de observar los datos. Enfoques frecuentistas pueden interpretarla como la distribución de los parámetros del modelo después de incorporar la información contenida en los datos. Esencialmente, combina la información inicial (distribución previa) con la información observada (verosimilitud) para proporcionar una nueva creencia sobre los parámetros. Por ejemplo, después de recolectar datos sobre la tasa de éxito de un tratamiento, la distribución posterior podría proporcionar una estimación más precisa de esa tasa de éxito.

**Parametrizar**

- Hace uso de los siguientes conceptos:

  + Datos

  + Evento incierto

  + Parametrizar: P(describir una simplificación de la realidad)

$$P(\text{evento incierto} | \text{datos})$$

Interpretación: Probabilidad de tener un buen modelo dado la información disponible.

**Pasos según Bayes, método científico**

1. Defina la pregunta de investigación.
2. Vea la información disponible.
   - ¿Es suficiente para contestar la pregunta?
     - Si: concluya, decida y tome acciones.
     - No: siga al paso 3.
3. Determine qué tipo de información adicional se necesita.
   - Diseñe un estudio.
   - Diseñe un experimento.
4. Haga el estudio en 3.
5. Use los datos en 4 para mejorar lo que se tiene hasta el momento.

Información previa: Paso 2.
Información posterior: Pasos 4-5.

**Teoremas**
$$P(A|B)=\frac{P(A\cap B)}{P(B)}$$
$$P(B|A)=\frac{P(B\cap A)}{P(A)}$$

- Regla de suma 
 
$$P(A\cup B)=P(A)+P(B)-P(A\cap B)$$

- Regla de multiplicacion
 
$$P(A\cap B)=P(A)\cdot P(B|A)$$
$$P(A\cap B)=P(B)\cdot P(A|B)$$

**Teorema de bayes**

$$P(A_i|B) = \frac{P(B|A_i) \cdot P(A_i)}{P(B|A_i) \cdot P(A_i) + P(B|\neg A_i) \cdot P(\neg A_i)}$$

$$\text{informacion posterior} \propto \text{informacion previa} \propto \text{verosimilitud (datos)}$$
$$P(\theta|y)=P(y|\theta)*P(\theta)$$
\(P(\theta|y)\) -> Modelo completo

\(P(y|\theta)\) -> Verosimilitud (peso en informacion/cuanto confio en los datos dado un parametro)

\(P(\theta)\) -> Prob. marginal del parametro


**Modelo de probabilidad completo**

+ \((x,y)\) -> Cantidades observables - informacion

+ \((\theta)\) -> Cantidad no observables - guardable - parametro 

+ \(y\) -> Evalua

+ \(Y\) -> Variable aleatoria

$$(\text{componen los modelos}|\text{parametros})$$

**Distribucion posterior**
$$P(\theta|y,x)$$

\((\theta)\) -> no observable

\((x,y)\) -> observable

**Metricas de evaluacion de modelos**

**Inferencia estadistica:** Obtener conclusiones de informacio (muestra/poblacion)

**Intercambiabilidad:** 

Muestra: \(y_1,...,y_n\) 

Para facilitar el analisis de modelo completo: \(y_1,...,y_n\) es intercambiable 

distribucion conjunta de \(y_1,..,y_n\) es invariante a cambios en los indices

**Ejemplo:** Cuando los datos son independientes

\(f(y_1,...,y_n)=f(y_1)***f(y_n)\)

\(f(y_1,...,y_n)=f(y_{d_1})***f(y_{d_n})\)

\(d_1=\text{cambios en los indices}\)

Algo es intercambiable si puedo cambiar el orden de la fila

**Modelo gerargico**

van a existir capas de informacion en los modelos

Primera capa:

\(Poisson(\mu_i)\)

\(i:Ebais\) -> Primer capa que observo

Segunda capa: describir la media

\(log(\mu_i)=(clima+vacunas+edad.promedio)\)

**Distribucion predictiva previa**
$$P(y)=\int P(\theta)*P(y|\theta)d\theta$$
**Consecuencia de la regla de bayes (prediccion)**

\(y\) es desconocida pero observable

\(\Theta=\)espacio parametrico

\(\tilde{y}=\) prediccion

\(P(y)=\int_{\Theta} \text {modelo completo}\)

\(P(\tilde{y}|y)=\int_{\Theta} P(\tilde{y}|\theta)*P(\theta|y)\)

\(P(\tilde{y}|\theta)\) -> Versimilitud

\(P(\theta|y)\) -> Posterior

\(\tilde{y}\) es independiente \(y\) dado el parametro

**Ejemplo:**  Prediccion para \(y\sim ber(\theta)\) 
$$P(\tilde{y}=1|y)=E[\theta|y]$$
$$P(y=1)=\theta$$
$$P(y=0)=1-\theta$$

**ODDS relativos**

comparacion de un evento con su complemento 

si \(\theta_1,\theta_2\): dos parametros

$$\frac{P(\theta_1)}{P(\theta_2)}$$

odds previos de \(\theta_1\) vs \(\theta_2\)
 
**Interpretación:** Un odds relativo mayor que \(1\) indica que el evento representado por \(\theta_1\) es más probable que el evento representado por \(\theta_2\). Si el odds relativo es igual a \(1\), significa que las probabilidades de ambos eventos son iguales. Si el odds relativo es menor que \(1\), entonces el evento representado por \(\theta_2\) es más probable que el evento representado por \(\theta_1\).

**Ejemplo: con un odd de 1.34**

Un odds relativo de \(1.34\) significa que el evento representado por \(\theta_1\) es aproximadamente \(1.34\) veces más probable que el evento representado por \(\theta_2\).

**Principios de verosimilitud**

Para un conjunto de datos, si hay dos modelos de probabilidad \(P(\theta|y)\) que tienen la misma versosimilitud entonces ambos modelos generara la misma evidencia para \(\theta\) - informacion

**Modelos de un parametro**

- Binomial
- Normal
- Exponencial
- Poisson 

**Supuestos**
- Intercambiabilidad o independencia para sintetizar la informacion contenida en \(y_1,...,y_n\) basta con tomar 
$$y=\sum y_i$$

- La escogencia de las previas no es unica y esta sujeta a parametrizaciones


ademas el estimador bayesiano es un promedio ponderado de la media empirica (mle) y la media de la previa
conforme el tamaño de muestra aumenta el estimador bayesiano se parece al frecuentista

**Criterios para seleccionar previas**

1. Interpretacion basada en la poblacion se selecciona la previa basada en todas las posibilidades donde vive el parametro

\(0<\theta<1\) -> \(Unif(0,1)\)

2. Interpretacion basada en el estado del conocimiento, se selecciona la previa usando estudios previos

**Propiedades de esperanza condicionada o de la torre**

\(\theta\): parametro aleatorio (bayes)

$$E[E[\theta|y]]=E[\theta]$$

\(E[]\) -> con respecto a \(y\)

\(E[\theta|y]\) -> con respecto a \(\theta\)

**Interpretacion:** la media de la media posterior es el valor esperado del parametro

$$Var(\theta)=E[Var(\theta|y)]+Var[E(\theta|y)]$$

\(Var(\theta)\) -> Var previa

\(Var(\theta|y)\) -> Var posterior 

**Interpretacion:** La varianza posterior es en promedio mas pequeña que la varianza previa 

\(Var(\theta)\geq Promedio[Var(\theta|y)]\)

Esto permite obtener estimadores \(\theta\) cada vez + precisos 

**Familias conjugadas propiedad**

Si la distribucion posterior tiene la misma forma parametrica que la distribucion previa decimos que la previa es una familia conjugada para la verosimilitud


**Modelo normal con varianza conocida**

Una unica observacion donde \(y\): observacion

- Modelo

\(y\sim N(\theta,\sigma^2)\), \(\sigma^2\): fijo (conocido)

$$P(y|\theta) = \frac{1}{\sigma \sqrt{2\pi}} e^{ -\frac{1}{2\sigma^2}(y-\mu)^2 }$$

\(P(y|\theta)\) -> es la verosimilitud normal en este caso

- Previa normal
$$P(\theta) \propto exp[-\frac{1}{2\tau_0^2} (\theta-\mu_0)^2]$$

\(\mu_0\) y \(\tau_0^2\)-> son hiperparametros

**Bayes:**

$$P(\theta|y) \propto P(y|\theta)*P(\theta)$$
$$P(\theta|y) \propto exp[-\frac{1}{2\sigma^2} (y-\theta)^2-\frac{1}{2\tau_0^2} (\theta-\mu_0)^2]$$

$$P(\theta|y) \propto exp[-\frac{1}{2\tau_1^2} (\theta-\mu_1)^2]$$

donde:

$$\text{media posterior}=\mu_1=\frac{\frac{1}{\tau_0^2}\mu_0+\frac{1}{\sigma^2}y}{\frac{1}{\tau_0^2}+\frac{1}{\sigma^2}}=E[\theta|y]$$

- Precision:
$$\frac{1}{\tau_1^2}=\frac{1}{\tau_0^2}+\frac{1}{\sigma^2}$$

\(\frac{1}{\tau_0^2}\) -> precision de la previa

\(\frac{1}{\sigma^2}\) -> presicion de los datos

Si la presicion previa es muy alta el estimador bayesiano es igual a la media de la previa

Asuma que la prediccion de \(y\) es bajo la esperanza condicional

- Prediccion de \(\tilde{y}\): \(P(\tilde{y}|y)\)

Con la version de propiedad de la torre

$$E[\tilde{y}|y]=E[E[\tilde{y}|\theta,y]|y]$$
Donde si quiero predecir uso \(\mu\) posterior de manera que de lo anterior obtenemos lo siguiente:
$$E[\tilde{y}|y]=E[\theta|y]=\mu_1$$
Por otra parte
$$Var(\tilde{y}|y)=E[Var(\tilde{y}|\theta,y)|y]+Var(E[\tilde{y}|\theta,y]|y)$$
$$Var(\tilde{y}|y)=Var(\theta|y)+E[\sigma^2|y]$$
$$Var(\tilde{y}|y)=\tau_1^2+\sigma^2$$
donde:

\(\tau_1^2\) -> var del modelo

\(\sigma^2\) -> var del individuo


**Caso para multiples observaciones**

Muestra: \((y_1,...,y_n)\)

Identicamente distribuidos \(y_i\sim N(\theta,\sigma^2)\)

asuminos la misma previa 
$$P(\theta|y) \propto P(y|\theta)*P(\theta)$$
$$P(\theta|y) \propto \prod_{i=1}^{n} P(y_i | \theta)*P(\theta)$$
$$P(\theta|y) \propto \prod_{i=1}^{n} P(y_i | \theta)*P(\theta)$$
$$P(\theta|y) \propto exp[-\frac{1}{2\tau_0^2} (\theta-\mu_0)^2] *\prod_{i=1}^{n}exp[-\frac{1}{2\sigma^2}(y_i-\theta)^2]$$
$$P(\theta|y) \propto exp[-\frac{1}{2}(\frac{(\theta-\mu_0)^2}{\tau_0^2}+\frac{1}{\sigma^2}\sum_{i=1}^n(y_i-\theta)^2)]$$

Como \(\bar{y}\) es un estadistico suficiente 

$$\bar{y}|\theta,\sigma^2 \sim N(\theta,\frac{\sigma^2}{n})$$

aplicando el desarrollo anterior pero utilizando \(\bar{y}\) en vez de \(y\) por lo que sutituimos \(\sigma^2\) por \(\frac{\sigma^2}{n}\) por lo que el desarrollo queda de la siguiente manera:

$$\mu_n=\frac{\frac{\mu_0}{\tau^2}+\frac{n}{\sigma^2}\bar{y}}{\frac{1}{\tau_0^2}+\frac{n}{\sigma^2}}=\text{media posterior}$$

- Presicion para este caso:

$$\frac{1}{t^2_n}=\frac{1}{\tau_0^2}+\frac{n}{\sigma^2}$$
**Caso Normal con varianza desconocida **

Asumimos \(y_i\) independiente e identicamente distribuidas donde \(y_i\sim N(\theta,\sigma^2)\) y \(\theta\): conocido y \(\sigma^2\): desconocido y aleatorio, si \(y=(y_1,...,y_n)\)


$$P(y|\sigma^2) =\prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} e^{ -\frac{1}{2\sigma^2}(y_i-\theta)^2 }$$

$$P(y|\sigma^2)\propto \sigma^{-n}exp(-\frac{n}{2\sigma^2}v)$$

donde \(v=\frac{1}{n}\sum_{i=1}^n (y_i-\theta)^2\) es el estadistico suficiente

asuma que \(\sigma^2\sim Gamma-Inv(\alpha,\beta)\)


Aplicamos bayes

$$P(\sigma^2|y)\propto P(\sigma^2)*P(y|\sigma^2)$$
$$P(\sigma^2|y)\propto (\sigma^2)^{-(\alpha+1)}e^{-\beta/\sigma^2} *\sigma^{-n}e^{-nv/2\sigma^2}$$

$$P(\sigma^2|y)\propto (\sigma^2)^{-(\alpha+1+n)}e^{-(\beta+\frac{nv}{2})/\sigma^2}$$

$$\sigma^2|y \sim Gamma-Inv(\alpha+n,\beta+\frac{nv}{2})$$

**Pasos hasta el momento**

- Previa

- Verosimilitud 

- Estadistico suficiente 

- Bayes

- Reconocimiento 

**Caso con la chi**

\(x\sim \chi^2_v\) -> \(\frac{1}{x}\sim Inv-\chi^2_v\)

Una \(Inv-\chi^2_v\) es una \(Gamma-Inv\) con \(\alpha=v/2\) y \(\beta=1/2\)

**Escalamiento**

Si \(Z\sim N(0,1)\) entonces \(\sigma Z\sim N(0,1)\) es una normal escalada 

Para la \(\chi^2\) inversa escalada tenemos los siguientes parametros \(\sigma_0^2\): es el parametro de escala y \(v_0\): grados de libertad dado que si \(y \sim Inv-\chi_{v0}^2\) entonces \(\sigma_0y \sim Inv-\chi^2(v_0,\sigma_0^2)\) es una inversa chi escalada

Recordatorio \(y_1,...,y_n \sim N(\theta,\sigma^2)\)

con previa \(\sigma^2\sim Inv-\chi^2(v_0,\sigma_0^2)\)
$$P(\sigma^2) \propto (\frac{\sigma_0^2}{\sigma^2})^{\frac{v_0}{2}+1}*exp(\frac{-v_0\sigma_0^2}{2\sigma^2})$$

con posterior 
$$P(\sigma^2|y) \propto P(\sigma^2)P(y|\sigma^2)$$
donde \(P(y|\sigma^2) \propto (\sigma^2)^{-n/2}exp(-\frac{nv}{2\sigma^2})\)

$$P(\sigma^2|y) \propto (\sigma^2)^{-(\frac{n+v_0}{2}+1)} *exp(\frac{-(nv+v_0\sigma_0^2)}{2\sigma^2})$$

$$\sigma^2|y \sim Inv-\chi^2(v_0+n,\frac{nv+v_0\sigma^2_0}{v_0})$$

$$(\sigma^2)^{-(\frac{n+v_0}{2}+1)} *exp(\frac{-v_0*(\frac{nv+v_0\sigma^2_0}{v0})}{2\sigma^2})$$
donde \((\frac{nv+v_0\sigma^2_0}{v0})\) es mi parametro de escala

**Ejemplo ejercicio de compu**

\(d_i\sim N(0,\sigma^2)\)

\(v=128902\)

asuminos \(\sigma^2\sim Inv-\chi^2(v_0=1)\) -> \((v_0=1,\sigma^2_0=1)\) estos son una escogencia arbitraria

ademas \(\sigma^2|d_i \sim Inv-\chi^2((v_0=1)+(n=672),\frac{nv+(v_0=1)(\sigma^2_0=1)}{(v_0=1)})\)

$$\propto Inv-\chi^2(673,(nv=\sigma^2_1)+1)$$

**Procedimiento**

- Genero 1000 \(\sigma^2 \sim \chi_{673}\)
- Se calcula \(z=1/\sigma^2\)
- Se calcula \(\sigma_1*z\) donde \(\sigma_1=\sqrt{nv+1}\)

**Caso poisson**

Pequeña anotacion 

La diferencia entre la escala y la tasa en una distribución exponencial se refiere a cómo se caracteriza la distribución y cómo se relacionan con los parámetros de la misma.

1. **Tasa (o tasa de ocurrencia):** En una distribución exponencial, la tasa, representada por \(\lambda\), indica la tasa media de ocurrencia de un evento por unidad de tiempo o espacio. Por ejemplo, si estamos modelando el tiempo entre llegadas de autobuses y \(\lambda = 0.2\), esto significa que, en promedio, llega un autobús cada \(5\) minutos (\(1/0.2\)).

2. **Escala (o tiempo medio de espera):** La escala, representada por \(\beta\), se refiere al tiempo medio de espera antes de que ocurra un evento. La escala es simplemente el inverso de la tasa, es decir, \(\beta = \frac{1}{\lambda}\). Utilizando el mismo ejemplo, si la tasa es \(\lambda = 0.2\), entonces la escala sería \(\beta = \frac{1}{0.2} = 5\) minutos. Esto indica que el tiempo medio de espera entre eventos es de \(5\) minutos.

En resumen, la tasa y la escala son dos formas de describir la misma distribución exponencial, pero se expresan de manera diferente. La tasa representa la frecuencia de ocurrencia de eventos por unidad de tiempo o espacio, mientras que la escala representa el tiempo medio de espera entre eventos.

\(y_1,...,y_n\) donde \(y_i\sim Poisson(x_i\theta)\) aqui poiss es una conjugada con \(\theta\sim Gamma(\alpha,\beta)\),  \(x_i\): es la expancion \(\theta\): es la tasa y en caso de que fuera \(\frac{1}{\theta}\): seria la escala. 
la posterior para esta anotacion queda de la forma \(\theta|y \sim Gammma(\alpha+\sum_{i=1}^{n}y_i,\beta + \sum_{i=1}^{n} x_i)\)

Prosiguiendo 

\(y \sim Poisson(\theta)\), \(\theta\): tasa

\(P(y|\theta)=\frac{\theta^ye^{-\theta}}{y!}/) 

si \(y=(y_1,...,y_n)\)

$$P(y|\theta)=\prod_{i=1}^{n}\frac{\theta^{y_i}e^{-\theta}}{y_i!}$$

$$P(y|\theta)\propto \theta^{t(y)}e^{-n\theta}$$
donde \(\sum_{i=1}^n y_i=n\bar{y}\)

la gamma es familia conjugada de la poisson \(\theta\sim Gamma(\alpha,\beta)\)

$$P(\theta)\propto \theta^{\alpha-1}e^{-\theta/\beta}$$

- posterior 
$$P(\theta|y) \propto P(\theta)*P(y|\theta)$$

$$P(\theta|y)\propto\theta^{\alpha-1} e^{-\theta\beta}*\theta^{t(y)}e^{-n\theta} $$

$$P(\theta|y)\propto\theta^{\alpha+t(y)-1} e^{-\theta(n+\beta)} $$

$$\theta|y \sim Gamma(\alpha+n\bar{y},n+\beta)$$
**Probabilidad predictiva previa**

$$P(y)=\frac{P(y|\theta)*P(\theta)}{P(\theta|y)}=\frac{Poisson(y|\theta)*Gamma(\theta|\alpha,\beta)}{Gamma(\theta|\alpha+y,1+\beta)}$$
$$P(y)=\frac{\Gamma(\alpha+y)\beta^{\alpha}}{\Gamma(\alpha)y!(1+\beta)^{\alpha+y}}$$
