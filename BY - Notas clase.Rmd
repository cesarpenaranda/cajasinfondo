# Pensamiento Bayesiano

Librerías:
```{r}
library(tidyverse)
library(LearnBayes)
```


## Ejemplo 1

- Pregunta de investigación: ¿Qué proporción de estudiantes universitarios duermen al menos 8 horas diarias? 

- Notación: $p$: proporción de estudiantes que duermen al menos 8 horas diarias. 

- Datos: Muestra de 27 estudiantes donde 11 sí durmieron al menos 8 horas ayer.

- Modelo: 
$$L(p)\propto p^s(1-p)^f$$
- Distribución posterior: Si $g(p)$ es la densidad previa de $p$, entonces:
$$g(p|\text{datos})\propto g(p)L(p)$$

Distribución Beta:
Uso: Se utiliza en estadística bayesiana como distribución de probabilidad a priori para modelar proporciones o tasas de éxito en pruebas de Bernoulli.

- Modelo: 
$$L(p)\propto p^s(1-p)^f$$
**Primera escogencia de previa $g(p)$**

```{r}
p <- seq(0.05,0.95,by = 0.1)
previa <- c(1,5.2,8,7.2,4.6,2.1,0.7,0.1,0,0) # fue a escogencia del experto 
previa <- previa / sum(previa)
plot(p, previa, type = "h", ylab="Probabilidad previa")
plot(p, previa, type = "l", ylab="Probabilidad previa",col="purple")
```

```{r}
datos_sleep <- c(11, 16)
datos_tot <- data.frame(p = p, previa = previa)
datos_tot <- datos_tot %>% mutate(posterior = previa* p^(11)*(1-p)^(16)) %>%
  mutate(posterior = posterior/sum(posterior)) 
round(datos_tot,2)
```

Comparación 1:
```{r}
# Graficar el primer conjunto 
plot(datos_tot$p, datos_tot$posterior, type="l",xlab = "p", ylab = "Probability", main = "Comparación:",col="blue")
# Agregar el segundo conjunto de datos al mismo gráfico
lines(datos_tot$p, datos_tot$previa, col = "red")
# Leyenda
legend("topright", legend = c("Posterior", "Previa"), col = c("blue", "red"), lty = 1)
```

Comparación 2 ggplot:
```{r}
datos_tot_long <- datos_tot %>%
  pivot_longer(previa:posterior,names_to = 'Type',values_to = 'Probability')

ggplot(datos_tot_long, aes(x = p, y = Probability, group = Type, color = Type)) +
  geom_line(linewidth = 3) +
  facet_wrap(~ Type, nrow =  2) +
  theme_minimal()

```

**Segunda escogencia de previa $g(p)$**

Escogencia de los parámetros de la Beta:
```{r}
quantile1 <- list(p = .5,x=.3) #x(p)=3 donde es la mediana de los datos, donde se acumula el 50% de los datos
quantile2 <- list(p=.9,x=.5)  #x(p)=.5 es el cuantil donde se acumula 90% de la prob
beta.select(quantile1,quantile2)
```

Comparación de densidades:
```{r}
a <- 3.26
b <- 7.19
s <- 11
f <- 16

x_values <- seq(0, 1, length.out = 1000)
df <- data.frame(x = x_values,
                 Prior = dbeta(x_values, a, b),
                 Likelihood = dbeta(x_values, s + 1, f + 1),
                 Posterior = dbeta(x_values, a + s, b + f))


ggplot(df, aes(x)) +
  geom_line(aes(y = Prior), linetype = "dashed", size = 1.5, color = "blue") +
  geom_line(aes(y = Likelihood), linetype = "dotted", size = 1.5, color = "green") +
  geom_line(aes(y = Posterior), size = 1.5, color = "red") +
  labs(x = "p", y = "Density") +
  theme_minimal() +
  scale_color_manual(values = c("blue", "green", "red")) +
  theme(legend.position = "top") +
  guides(color = guide_legend(title = "Density"))

```

Para responder parcialmente la pregunta de investigación:
```{r}
1 - pbeta(0.5, a + s, b + f)
```
$$P(p>1/2)\approx0.07$$

es decir hay una probabilidad aproximadamente de 7% de que más de la mitad de los estudiantes universitarios duerman más de 8 horas diarias. O bien, si se quiere calcular la probabilidad de que la proporción de estudiantes sea mayor a lo observado:

```{r}
1 - pbeta(11/27, a + s, b + f)
```
Lo observado:
$$p_0=11/27$$
$$P(p>p_0)\approx0.36$$
apartir de lo anterior surge la posible hipotesis
H0: sera que p es mayor que lo observado?
p>p_0

$$P(H_0)=P(p>p_0)=0.36$$
Intervalo de credibilidad para $p$:

```{r}
qbeta(c(0.05, 0.95), a + s, b + f)
```

en donde se infiere que $p$ tiene una probabilidad del 95% de estar ubicado entre esos dos valores. El resultado anterior que es exacto, se puede aproximar usando simulación:

```{r}
ps <- rbeta(1000, a + s, b + f)
hist(ps,xlab="p",main="")

#para graficarlo mas suave con prob
hist=hist(ps, breaks = 10, main = " ", xlab = "Valores")
p1=hist$mids
counts1=hist$counts
den1 <- counts1 /sum(counts1) 
plot(p1, den1, type = "l", ylab="Probabilidad")
```

y la probabilidad de que $p>0.5|\text{datos}$ se puede aproximar empíricamente:

```{r}
sum(ps >= 0.5)/1000
```

y el intervalo de credibilidad correspondiente:
```{r}
quantile(ps, c(0.05, 0.95))
```
## Para estimacion:
calcular un estadistico que estime p
podemos utilizar medidas centrales como la media o la mediana en caso de que la distribucion sea muy asimetrica

encontramos que:
```{r}
mean(ps)
```
estimador de la media 
$$\hat{p}=0.374$$
podemos encontrar que la moda esta entre 0.35 y 0.40
moda:
$$\frac{a-1}{a+b-2}=\frac{14.26-1}{14.6+23.19-2}=0.374$$
### Predicción
$$P(\bar{y} |y)$$
$$\int P(p|y)*P(\bar{y}|p)dp$$
Bajo la primera previa:

```{r}
p <- seq(0.05, 0.95, by=.1)
prior <- c(1, 5.2, 8, 7.2, 4.6, 2.1, 0.7, 0.1, 0, 0)
prior <- prior/sum(prior)
m <- 20
ys <- 0:20
pred <- pdiscp(p, prior, m, ys)
round(cbind(0:20,pred),3)
```

Bajo la segunda previa (beta):

```{r}
fy <- choose(m,ys)*beta(a+ys,b = b+m-ys)/beta(a,b)
ab <- c(3.26, 7.19)
pred <- pbetap(ab, m, ys)
```

O por simulación:
```{r}
p <- rbeta(1000, 3.26, 7.19)
y <- rbinom(1000, 20, p)
table(y)
```

```{r}
freq <- table(y)
ys <- as.integer(names(freq))
predprob <- freq / sum(freq)

df <- data.frame(ys = ys, predprob = predprob)


ggplot(df, aes(x = ys, y = predprob)) +
  geom_line(stat = "identity", type = "h", color = "blue", size = 1.5) +
  labs(x = "y", y = "Predictive Probability") +
  theme_minimal()

```
Cálculo de intervalo de credibilidad al 90% usando la probabilidad predictiva anterior:

```{r}
dist <- cbind(ys,predprob)
covprob <- .9
discint(dist,covprob)
```

## Ejemplo 2 (Ejercicio 5, Capítulo 2, Albert)
la variable es una variable continua que se mide en pulgadas, ademas es una tasa ya que se mide por año, osea pulgadas por año 
$$y_1,...,y_n\sim N(\mu,10^2)$$
Previa:
```{r}
previa_mu <- data.frame(mu = seq(20,70,by = 10),
                        gmu = c(.1,.15,.25,.25,.15,.1)) #gmu= a la probabilidad
```

Datos:
```{r}
y_snow <- c(38.6,42.4,57.5,40.5,51.7,67.1,33.4,
            60.9,64.1,40.1,40.7,6.4)
y_bar <- mean(y_snow)
```

Verosimilitud:
$$L(\mu)=P(y|\mu)\propto P(y|\mu)$$$$$$
$$y\sim N(\mu,\sigma^2/n)$$
```{r}
posterior_mu <- previa_mu %>%
  mutate(like = exp(-12/(2*10^2)*(mu-y_bar)^2))
```

Posterior:
```{r}
posterior_mu <- posterior_mu %>% 
  mutate(post = gmu*like/sum(gmu*like))
posterior_mu
```

Intervalo de credibilidad al 80% para $\mu$:

```{r}
dist_mu <- posterior_mu %>% select(mu,post)
covprob <- .8
discint(dist_mu,covprob)
```
Interpretacion: si yo quiero predecir las pulgadas al año, podemos decir que va a estar entre 40 y 50 con un 99% de pobabilidad

También se podría estimar el intervalo de credibilidad vía simulación:

```{r}
muestra_mu <- sample(dist_mu$mu,size = 1000,replace = T,prob = dist_mu$post)
quantile(muestra_mu,probs = c(0.1,0.9)) #aqui estoy calculando un intervalo de credibilidad al 80%
```


## Ejemplo 3 (Evaluación Práctica 1)

Los siguientes datos simulan el sexo de 200 recién nacidos, en donde 1 denota niño y 0 denota niña.

```{r,echo=FALSE}
set.seed(10)
recien_n <- rbinom(n = 200,size = 1,prob = 111/200)
```

```{r}
recien_n
```

Vamos a utilizar dos distintas formas de definir numéricamente la previa:

### Previa 1

Se va a definir una previa usando una grilla de tamaño 1000 con 100000 muestras:
```{r}
set.seed(10)
p_prev_sample <- runif(n = 100000)
histo_1 <- hist(p_prev_sample,breaks = 1000)


p_post1 <- data.frame(p = histo_1$breaks[-1],prev = histo_1$counts)

p_post1 <- p_post1 %>% mutate(prev = prev / sum(prev))
```

Cálculo de probabilidad posterior y valor de $p$ que la maximiza:

```{r}
y <- sum(recien_n)
n_tot <- length(recien_n)
p_post1 <- p_post1 %>% mutate(post = prev * p^y*(1-p)^(n_tot-y)) %>%
  mutate(post = post / sum(post))
plot(p_post1$p,p_post1$post,type='l')
```

Valor que maximiza la posterior:
```{r}
p_post1$p[which.max(p_post1$post)]
```

### Previa 2

Se va a definir una previa usando una grilla de tamaño 10 con 1000 muestras:
```{r}
set.seed(10)
p_prev_sample <- runif(n = 1000)
histo_2 <- hist(p_prev_sample,breaks = 10)


p_post2 <- data.frame(p = histo_2$breaks[-1],prev = histo_2$counts)

p_post2 <- p_post2 %>% mutate(prev = prev / sum(prev))
```

Cálculo de probabilidad posterior y valor de $p$ que la maximiza:

```{r}
p_post2 <- p_post2 %>% mutate(post = prev * p^y*(1-p)^(n_tot-y)) %>%
  mutate(post = post / sum(post))
plot(p_post2$p,p_post2$post,type='l')
```

Valor que maximiza la posterior:
```{r}
p_post2$p[which.max(p_post2$post)]
```

De ahora en adelante se utilizará la primera previa para calcular la muestra de tamaño 10000 de la distribución posterior:

```{r}
muestra_post <- sample(p_post1$p,replace = T,size = 10000,prob = p_post1$post)
```

Cálculo del intervalo de credibilidad al 90%:

```{r}
quantile(muestra_post,probs = c(0.05,0.95))
```

de donde se deduce que con una probabilidad de 90%, el parámetro $p$ (proporción de niños) esté contenido en el intervalo $(0.55,0.67)$.

Ahora vamos a estimar la probabilidad posterior de que un recién nacido fuera de la muestra sea niño:

```{r}
y_post <- rbinom(n = 1000,prob = muestra_post,size = 1)

prob_prediccion <- sum(y_post)/1000
prob_prediccion
```


# Modelos de un parámetro

## Ejemplo 1

Análisis del ejemplo de la página 37 del Gelman.

Un estudio alemán concluyó que de un total de 980 nacimientos con condición de placenta previa, 437 nacieron niñas.

Pregunta de investigación: Qué tan evidente es la afirmación de que en la población de nacimientos de placenta previa, la proporción de nacimientos femeninos sea menor a 0.485?

## Primera previa

Suponga que $\theta$: proporción de niñas que nacieron bajo la condición de placenta previa. Usando una previa uniforme para $\theta$ en (0,1), la media posterior es $Beta(438,544)$:

```{r}
a_post <- 438
b_post <- 544
```

por lo tanto la media y la desviación posterior del parámetro $\theta$ es:

```{r}
media_post <- a_post/(a_post+b_post)
sd_post <- sqrt(media_post*(1-media_post)/983)
```

Como la posterior es beta, se puede calcular directamente que un intervalo de credibilidad al 95% es $(0.415,0.477)$, lo cual se puede comprobar de manera aproximada al calcular:

```{r}
pbeta(0.477,shape1 = a_post,shape2 = b_post)-
  pbeta(0.415,shape1 = a_post,shape2 = b_post)
```

Por la justificación vista en clase, se puede aproximar la distribución posterior con una distribución normal y calcular directamente los límites del intervalo de credibilidad a como sigue:

```{r}
cuantil0975_norm <- media_post+qnorm(0.975)*sd_post
cuantil025_norm <- media_post-qnorm(0.975)*sd_post
c(cuantil025_norm,cuantil0975_norm)
```

Asimismo, podemos obtener una muestra aleatoria de la posterior de la sifuiente forma:

```{r}
theta_post <- rbeta(1000,shape1 = a_post,b_post)
hist(theta_post)
```

y así calcular el mismo intervalo de credibilidad:

```{r}
quantile(theta_post,probs = c(0.025,0.975))
```

y un estimador puntual bayesiano para $\theta$:

```{r}
median(theta_post)
```

Por otro lado también podemos usar la reparametrización $\phi=\log\left(\frac{\theta}{1-\theta}\right)$ para aplicar la aproximación normal sobre un parámetro totalmente definido en $\mathbb R$:

```{r}
phi_post <- log(theta_post/(1-theta_post))
hist(phi_post)
phi_mean <- mean(phi_post)
phi_sd <- sd(phi_post)
```

y de esta forma aproximar el mismo intervalo de credibilidad para $\theta$, usando la transformación logística:

```{r}
logistico <- function(u){
  exp(u)/(1+exp(u))
}

logistico(phi_mean+qnorm(0.975)*phi_sd)
logistico(phi_mean-qnorm(0.975)*phi_sd)
```

También podemos hacer inferencia sobre la razón niña/niño ($\theta/(1-\theta)$):

```{r}
razon_post <- theta_post/(1-theta_post)
quantile(razon_post,probs = c(0.025,0.975))
```

La pregunta de investigación puede ser contestada al calcular lo siguiente e interpretarlo de forma apropiada según lo comentado en clase:

```{r}
pbeta(0.485,shape1 = a_post,shape2 = b_post)
```

Asimismo, podemos calcular el *periodo de retorno* del evento principal al calcular:

```{r}
1/pbeta(0.485,shape1 = a_post,shape2 = b_post,lower.tail = F)
```

## Ejemplo 2

Desarrollamos una solución alternativa al ejemplo en la sección 3.2 del Albert:

En este caso se tiene datos correspondientes a las diferencias entre los resultados de partidos de fútbol americano y "point spreads":

```{r}
library(LearnBayes)
data("footballscores")
attach(footballscores)
d <- favorite-underdog-spread
```

Si asumimos un modelo normal en las diferencias con media 0 y varianza $\sigma^2$, el estadístico suficiente respectivo es:

```{r}
v <- sum(d^2)
n <- length(d)
show(v)
```

Asumiendo una distribución previa $Inv-\chi^2(v_0=1, \sigma^2_0=1)$, según lo visto en clase, la probabilidad posterior de $\sigma^2$ es $Inv-\chi^2(v_1=n+1, \sigma^2_1=nv+1)$ en donde:

```{r}
v1 <- n+1
sigma1 <- sqrt(n*v+1) 
```

Simulamos una muestra de tamaño 1000 de la distribución posterior de $\sigma^2$. Noten que la simulación usa las propiedades de una chi-cuadrado inversa.

```{r}
Xpost <- rchisq(n = 1000,df = n+1) 
Z <- 1/Xpost
sigma2_post <- sigma1*Z
```

O bien pueden usar la siguiente función que simula las muestras directamente:

```{r}
library(LaplacesDemon)
sigma2_post2 <- rinvchisq(n = 1000,df = v1,scale = sigma1/v1)
```

Noten que el parametro de escala en esta función hay que dividirlo por los grados de libertad para que sea igual al que definimos en clase. En ambos casos se puede calcular un intervalo de credibilidad al 95% y un estimador puntual de $\sigma^2$:

```{r}
quantile(sigma2_post, probs = c(0.025, 0.5, 0.975))
quantile(sigma2_post2, probs = c(0.025, 0.5, 0.975))
```

## Ejemplo 3

Considere el ejemplo de la página 45 del Gelman, en donde se modela la tasa de muerte producto del asma en una ciudad de Estados Unidos. La población de la ciudad es de 200000 personas. En un año han fallecido 3 personas, dando una tasa cruda de:

```{r}
3/200000
```

1.5 muertes por 100000 habitantes. Asumimos que el conteo de muertes $y\sim Poisson(2\theta)$ indicando que la tasa se mide en número de casos por 100000 habitantes, con una población expuesta de $2\times 100000$ habitantes. Asumiendo una previa $\theta \sim Gamma(3,5)$ se tiene un valor esperado (previo) de la tasa de muerte de:

```{r}
3/5
```

por cada 100000 habitantes. Note que en este caso hay una probabilidad previa de más de un 97.5% de que la tasa de muerte esté por debajo de 1.44:

```{r}
pgamma(1.5,shape = 3,rate = 5)
```

Una muestra posterior de $\theta$ asumiendo que $y=3$ es:

```{r}
theta_post <- rgamma(n = 1000,shape = 6,rate = 7)
```

y gráficamente:

```{r}
hist(theta_post)
```

y un intervalo de credibilidad al 95% sería:

```{r}
quantile(theta_post, probs = c(0.025, 0.5, 0.975))
```

Si se observara la misma cantidad de muertes por año en la misma ciudad en un periodo de 10 años, y asumimos que la población es constante, la posterior la podemos muestrear de la siguiente forma:

```{r}
theta_post2 <- rgamma(n = 1000,shape = 33,rate = 25)
hist(theta_post2)
```

y el intervalo de credibilidad correspondiente para $\theta$ al 95% sería:

```{r}
quantile(theta_post2, probs = c(0.025, 0.5, 0.975))
```

## Evaluación Práctica 2

Tiempo de quemado de las cinco bombillas:

```{r}
y <- c(751,594,1213,1126,819)
```

Simulación de la distribución posterior de $\theta$:

```{r}
n_tot <- length(y)
s <- sum(y)
theta_post <- rgamma(n = 1000,shape = n_tot,rate = s)
hist(theta_post)
```

Muestra posterior de $\lambda$:

```{r}
lambda_post <- 1/theta_post
hist(lambda_post)
```

La probabilidad posterior de que $\lambda$ exceda las 1000 horas se puede estimar:

```{r}
sum(lambda_post>1000)/1000
```

La probabilidad predictiva posterior del tiempo de quemado de una bombilla es:

```{r}
y_tilde <- rexp(n = 1000,rate = 1/lambda_post)
y_tilde_freq <- hist(y_tilde,breaks = 20)
y_tilde_x <- y_tilde_freq$mids
y_tilde_post <- y_tilde_freq$counts/1000
plot(y_tilde_x,y_tilde_post,type='l',ylab = 'Prob. Post.')
```

Intervalo de credibilidad al 90% para el tiempo de quemado:

```{r}
quantile(y_tilde,probs = c(0.05,0.95))
```

# Modelos de varios parámetros

## Ejemplo 1. Página 66, Gelman.

Cargamos la librería MASS, que contiene los datos del experimento de Simon Newcomb en 1882:

```{r}
library(MASS)
data("newcomb")
```

Recuerden que se busca estimar la velocidad media en la que la luz viaja en una distancia de 7442 metros.

Histograma de los datos observados por Newcomb:
```{r}
hist(newcomb,breaks = 40)
```

donde se nota un cierto grado de simetría en la densidad excepto por los dos valores negativos de la serie.

Con el fin de generar una muestra posterior multivariada de $(\mu,\sigma^2)$, primero generamos la muestra posterior de $\sigma^2$:

```{r}
s2 <- var(newcomb)
sigma2_pre <- rchisq(n = 1000,df = 65)
sigma2_post <- sqrt(s2)/sigma2_pre
hist(sigma2_post)
```

la cual es una muestra de una variable según $Inv-\chi^2(n-1,s^2)$. La muestra de la media $\mu|\sigma^2,y$ es:

```{r}
n_tot <- length(newcomb)
ybar <- mean(newcomb)
mu_post <- rnorm(n = 1000,mean = ybar,sd = sqrt(sigma2_post/n_tot))
hist(mu_post)
```

Un intervalo de credibilidad al 90% para $\mu$ (dado que $\sigma$ es fijo) es:

```{r}
quantile(mu_post,probs = c(0.05,0.95))
```

Vale la pena compararlo con un intervalo de credibilidad para $\mu$ sin considerar $\sigma$ fijo:

```{r}
ybar + c(-1,1)*qt(0.95,df = 65)*sqrt(s2/n_tot)
```

el cual por supuesto va a ser más disperso.

La distribución posterior predictiva de una nueva observación del experimento, se infiere a través de una muestra:

```{r}
y_tilde_post <- rnorm(n = 1000,mean = mu_post,sd = sqrt(sigma2_post))
hist(y_tilde_post)

quantile(y_tilde_post,probs = c(0.05,0.95))
```
y este ultimo sería el intervalo de credibilidad al 90% para la nueva observación $\tilde y$.

## Ejemplo 2: sección 4.2, Albert.

Datos de tiempos (en minutos) de corredores de maratón con edades entre 20 y 29 años:

```{r}
library(LearnBayes)
data("marathontimes")
attach(marathontimes)
hist(time)
```

Asimismo se puede graficar una [figura de contorno](https://en.wikipedia.org/wiki/Contour_line):

```{r}
d = mycontour(normchi2post, c(220, 330, 500, 9000), time,xlab="mean",ylab="variance")
```

Por otro lado generamos una muestra posterior de los dos parámetros de interés, para incorporarlos en el gráfico anterior:

```{r}
S <- sum((time-mean(time))^2)

n <- length(time)

sigma2_post <- S/rchisq(1000,n-1)
hist(sigma2_post)
mu_post <- rnorm(n = 1000,mean = mean(time),sd = sqrt(sigma2_post/n))
hist(mu_post)
```

Incorporamos la muestra en el gráfico de la log-densidad-posterior:

```{r}
d = mycontour(normchi2post, c(220, 330, 500, 9000), time,xlab="mean",ylab="variance")
points(mu_post,sigma2_post)
```
Intervalos de credibilidad para $\mu|\sigma^2, y$ (en horas) y para $\sigma^2|y$ son:

```{r}
quantile(mu_post,c(0.025,0.975))/60
quantile(sqrt(sigma2_post),c(0.025,0.975))
```

## Ejemplo 3: sección 4.3 del Albert

1447 adultos mostraron su preferencia de voto a Bush: $y_1=727$, Dukakis: $y_2=583$ y $y_3=137$ a otros candidatos para la elección presidencial de 1988. Se asume que $y_1,y_2,y_3$ sigue una distribución multinomial con parámetros $\theta_1,\theta_2,\theta_3$ respectivamente. Entonces la distribución posterior de estos parámetros sigue una distribución Dirichlet, simulados de la siguiente forma:

```{r}
alpha <- c(728,584,138)
theta_post <- rdirichlet(1000,alpha)
```

con histogramas:
```{r}
hist(theta_post[,1])
hist(theta_post[,2])
hist(theta_post[,3])
```

Es de interés hacer inferencia acerca de la diferencia en la probabilidad de voto de Bush vs Dukakis: $\theta_1-\theta_2$:

```{r}
hist(theta_post[,1]-theta_post[,2])
```

y un intervalo de credibilidad al 95% para esta diferencia es:
```{r}
quantile(theta_post[,1]-theta_post[,2],c(0.025,0.975))
```

Por lo tanto con una probabilidad del 95% la diferencia siempre faorece al primer candidato. Es más, si estimamos la probabilidad de que el segundo candidato resulte ganador:

```{r}
sum(theta_post[,1]-theta_post[,2]<0)/1000

```

Esta probabilidad es nula.

## Evaluación Práctica 3