---
title: "Resumen-Experimentos"
author: "Cesar Peñaranda"
output: html_document
date: "2023-10-09"
---

## Distribuciones / Generalidades
- Gamma 

Las variables continuas positivas usualmente tienen una distribucion asimetrica, debido al limete en cero, presentan una relacion entre la media y la varianza, la funcion gamma se pude utilizar para modelar

- Binomial

Variable respuesta es binaria

- Binomial negativa

Es útil cuando se busca saber cuántos intentos son necesarios antes de alcanzar un objetivo en situaciones como lanzar una moneda hasta obtener 3 caras o jugar a los bolos hasta derribar 5 pines. ademas se puede usar tambien en conteos

- Poisson

La distribución de Poisson es como contar cosas raras que suceden poco a
poco. por ejemplo que estás mirando a través de una ventana y cuentas
cuántos coches pasan por la calle en una hora. La distribución de
Poisson te ayuda a saber la probabilidad de que pase un número
específico de coches en ese tiempo.

- Ejemplo moscas

En este caso se cuenta el número de moscas en un momento y lugar
específico bajo un cierto tratamiento. Este número teóricamente puede ir
de cero a infinito, siendo en general los conteos obtenidos números no
muy grandes, por lo que la distribución es genuinamente Poisson y no
convendría aproximarla a la normal por el hecho de no tener conteos muy
grandes.

- En el ejemplo de escarabajos

Es importante notar que estos efectos no significan lo mismo que en un modelo con distribución
normal, es decir, el efecto no se define como la diferencia entre la media condicional y la media
general, sino que es más bien un coeficiente que se agrega al intercepto.

- Algunas generalidades

**Interpretacion de distribucion de Y:** se asume que la distribucion de \(y\): numero de caidas, condicional al trat, sexo, el valor de balance y fuerza, es poisson con esperanza \(\lambda_{i,j,B,F}\)

$$Y|i,j,B,F\sim Poi(\lambda_{i,j,B,F})$$

**Interpretacion de funcion de enlace:** la funcion de enlace entre la parte lineal (componente sistematico) y el valor esperado de la distribucion condicional es logaritmica

**Error \(\epsilon\):** agragamos el error solo cuando tengo un modelo normal que esta en funcion de \(y_{ij}\) no un glm que esta descrito en funcion de la esperanza, osea si lo escribo solo si lo estoy diciendo en terminos de \(y_{ij}\)

- **Grados de libertad** en lmer

Entonces se tienen a(r-1) grados de libertad, donde a es el número de métodos y r el número de lotes por cada método. En este caso 3*(3-1)=6. El error de subparcela se calcula con n-p-gl.

parcela, donde p es el número de coeficientes (1 de intercepto, 2 de métodos, 3 de temperaturas, 6 de interacción, son 12 coeficientes), por lo que el error de parcela tiene 36-12-6=18 grados de libertad. La probabilidad para la interacción se calcula con el error de subparcela.

- Para diseños anidados el analisis que podemos hacer 

Podemos probar la variabilidad que agrega cada nivel(lmer) 

Podemos obtener los intervalos de confianza(confint)

Podemos probar el efecto de algun factor(anova)

Esto debido al factor aleatorio que se le atribuye, por lo cual no tiene sentido hacer comparaciones directas ya que los factores que se tienen son una muestra de una poblacion mas amplia

## Librerias 
```{r eval=FALSE}
library(lme4) #para la funcion lmer 
library(emmeans) #para las comparaciones
library(dplyr) #para el mutate
library (AER) #para el dispersion test
library(MASS) #para binomial negativa
library(lattice) #para algunos graficos
```

## Creacion de bases
```{r eval=FALSE} 
trigli=c(142.3, 144.0, 148.6, 146.9, 142.9, 147.4, 133.8,
133.2, 134.9, 146.3, 145.2, 146.3, 125.9, 127.6,
108.9, 107.5, 148.6, 156.5, 148.6, 153.1, 135.5,
138.9, 132.1, 149.7, 152.0, 151.4, 149.7, 152.0,
142.9, 142.3, 141.7, 141.2)
dia=factor(rep(1:4,each=8))
maq=factor(rep(c("A","B","C","D"),4,each=2))
base=data.frame(trigli,dia,maq)

```

```{r eval=FALSE}
correr = rep("correr",10)
jump = rep("jump",10)
cuerda = rep("cuerda",10)
trat =c(correr,jump,cuerda)
resp = c(27,42,27,59,64,35,60,
         36,38,54,36,31,45,47,
         40,10,21,10,19,28,24,
         11,37,45,39,15,29,12,
         7,14)
bloque = c(1:10,1:10,1:10)
h=cbind(bloque,trat,resp)
h=as.data.frame(h)
```

- Formar una columna apartir de dos columnas
```{r eval=FALSE}
base$pulpa_lote=paste(base$metodo,base$lote,sep = "-")
```

- **Sumamente util para diseños anidados**
```{r eval=FALSE}
base$pulpa_lote=base$metodo:base$lote
```

## Graficos 

- Boxplot con ggplot2
```{r eval=FALSE}
library(ggplot2)
ggplot(base,aes(lote,prod)) + #base del grafico 
  geom_boxplot() + #tipo de grafico 
  geom_hline(yintercept = mean(base$prod), color = "red", linetype = "dashed") + #agregar la media general
  stat_summary(fun = mean, geom = "point", shape = 16, size = 3, color = "red") #agregar medias condicionales
```

- Boxplot con lattice
```{r eval=FALSE}
bwplot(res~temp,data = base)
```

- Boxplot basico
```{r eval=FALSE}
boxplot(conteo~trat1,data = base)

media=tapply(base$conteo,base$trat1,mean)
#agrega puntos en las medias 
points(media, col = "red", pch = 16)
#agrega una linea a la media general
abline(h = mean(base$conteo), col = "blue")
```
- Grafico de puntos agrupado 
```{r eval=FALSE}
library(lattice)
dotplot(trigli~maq|dia,xlab="día",ylab="triglicéridos")
```
- Sin agrupar util para comparar directamente
```{r eval=FALSE}
xyplot(trigli~maq,group=dia,data = base,auto.key=list(columns=4))
```

- Muy util para ver interaccion
```{r eval=FALSE}
xyplot(trigli~maq,group=dia,type="a",data = base,auto.key=list(columns=4))
```

```{r eval=FALSE}
#En los diseños de parcela divididas se pone más énfasis al factor que está en la subparcela, por lo que ese factor debe colocarse en groups, mientras que el factor de parcela se coloca en el eje X.
xyplot(res~lote|metodo,groups = temp,type=c("a","p"),data = base,auto.key=list(columns=4))
```

- Grafico de escarabajos
```{r eval=FALSE}
xyplot(M/(M+H)~parcela,groups=tipo,type=c("p","a"),
auto.key=list(columns=2),ylab="proporción de machos",data=base)
```

- Plot supuesto de equidispercion
```{r eval=FALSE}
res=residuals(mod1,type="response")
plot(log(res^2)~log(fit))
abline(0,1,col="red")
```

## Modelos 

**Griegas/coeficientes**

**Latinas/variables**  

- Ejemplo tasas **poisson cancer**

$$log(\lambda_{F,E}/P)=\beta_0+\tau_2F+\delta E+\gamma FE$$
Donde \(F\) es una variable auxiliar que toma valor 1 si son fumadores y 0 si no lo son, \(E\) grupo medio del grupo de edad y \(P\) es el numero de personas año. se asume una distribucion poisson para el numero de muertes  dado un grupo de fumado (si/no) y la edad, con esperanza \(\lambda_{F,E}\)

**componente aleatorio:** La funcion de enlace es logaritmica y la parte aleatoria es la distribucion condicional al numero de muertes dado el grupo de fumado y la edad, la cual se asume poisson con parametro \(\lambda_{F,E}\)
```{r eval=FALSE}
#Modelo utilizado
mod1=glm(muertes~offset(log(den))+edad*fumado,family = poisson,data=base)
```
**Interpretacion del OR:** La tasa de muertes por enfermedad coronaria de medicos es 50% mayor entre fumadores comparada con la de los no fumadores, cuando se fija el grupo de edad

- Ejemplo **caidas**

$$log(\lambda_{i,j,B,F})=\beta_0+\tau_i+\gamma_j+\beta_1B+\beta_2F+(\tau\gamma)_{ij}+\beta^*_{1,i}B+\beta^*_{2,i}F$$
El coeficiente \(\tau_i\) esta asociado al i-esimo tratamiento, con \(\tau_1=0\), mientras que el coeficiente \(\gamma_j\) esta asociado al j-esimo sexo con,\(\gamma_1=0\), la interaccion entre ambos se denota por \((\tau\gamma)_{ij}\), los coeficientes \(\beta_1\) y \(\beta_2\) corresponde a las variables balance y fuerza, respectivamente, mientras que \(\beta^*_{1,i}\) y \(\beta^*_{2,i}\) son las interacciones de balance y fuerza con el i-esimo tratamiento, respectivamente

- Ejemplo modelo **poisson suma nula**

$$lod(\lambda_j)=\beta_0+\tau_j$$ 
restriccion:
$$\tau_1+\tau_2+\tau_3+\tau_4=0$$

- Ejemplo de **ecuacion estimada**, propenciones log (trat referencia)

$log(\frac{p}{1-p})=-2.43+2.15D_{200}+2.29D_{400}+3.05D_{800}$

- **Ecuacion estimada** para caso continuo

$log(\frac{p}{1-p})=-1.41+0.003D$

- Ejemplo **hojas** / propenciones
```{r eval=FALSE}
mod1=glm(cbind(mal,thojas-mal)~dosix,family = binomial,data = base)
```
- Ejemplo binomial negativa
```{r eval=FALSE}
#binomial negativa library(MASS)
glm.nb(res~trat1+trat2,data=base)
```

- Modelo quasipoisson
```{r eval=FALSE}
mod2=glm(conteo~trat1,family = quasipoisson,data = base)
``` 

- Ejemplo de **colorantes** modelo mixto
$$y_{ij}=\beta_0+\delta_i+\epsilon_{ij}$$

\(y_{ij}=\) la j-esima observacion dentro del i-esimo lote

\(\delta_{i}=\) efecto del i-esimo lote o del i-esimo sujeto del nivel 2 (error del nivel 2)

Esperanza condicional dado el lote es
$$E[Y|i]=\mu_i=\beta_0+\delta_i$$
```{r eval=FALSE}
#Modelo utilizado
library(lme4)
mod1=lmer(prod~(1|lote),data = base) # para los efectos aleatorios en este caso (1|lote) el 1 representa el promedio
```

- Ejemplo de **espectofotometro** modelo mixto

la k-esima muestra dentro del j-esimo dia, para la i-esima maquina se expresa como
$$y_{ijk}=\beta_0+\tau_i+\delta_j+(\tau\delta)_{ij}+\epsilon_{ijk}$$
\(\tau_i=\) efecto de la i-esima maquina

\(\delta_j=\) efecto del j-esimo dia 

\((\tau\delta)_{ij}=\) efecto de interaccion para la i-esima maquina en el j-esimo dia
 
Esperanza condicional dado el dia y la maquina
$$E[Y|ij]=\mu_{ij}=\beta_0+\tau_i+\delta_j+(\tau\delta)_{ij}$$
```{r eval=FALSE}
#Modelo utilizado
mod1=lmer(trigli~1+maq+(1|dia)+(1|dia:maq),data = base)
```

- Ejemplo de **papel** multinivel

**Nivel 1 (parcela completa)**

*Unidad*: fraccion del lote 

*Factor*: metodo (tratamientos principales) 

**Nivel 2 (sub-parcela)**

*Unidad*: lote 

*Factor*: temperatura

$$yijk=\mu+\alpha_i+\beta_i+(\alpha\beta)_{ij}+\delta_k+\epsilon_{ijkl}$$
\(\alpha_i=\) efecto del i-esimo metodo

\(\beta_i=\) efecto de la j-esima temperatura

\((\alpha\beta)_{ij}=\) efecto de interaccion para el i-esimo metodo con la j-esima temperatura
 
\(\delta_{k}=\) efecto del lote o error de parcela

\(\epsilon_{ijkl}= \) error de sub-parcela 

donde el efecto del lote o error de parcela:
$$\delta\sim N(0,\sigma^2_{\delta})$$
Sintaxis para el modelo

lmer(Y~F2*F1+(1|lote)), donde F2 indica el factor del Nivel 2 que, en este caso, es el método y F1 es el factor del Nivel 1 que es la temperatura.
```{r eval=FALSE}
#Modelo utilizado
mod1=lmer(res~metodo*temp+(1|lote),data = base)
```

- Ejemplo del caso **papel** que incluia bloques

Modelo con interacción entre metodo y temp, dia como bloque.directamente con la función lmer y día como un término aleatorio de Nivel 3, para esto se usa (1|dia/lote1), de esta forma se está diciendo que los lotes son de Nivel 2 y están dentro de los días que son de Nivel 3.
```{r eval=FALSE}
mod1=lmer(res~metodo*temp+(1|dia/lote1),data = base)
#lote1 era los lotes que se podian sacar por dia
```


**interpretacion de los resultados en este caso: ** no se detectaron diferencias en todos los pares; especificamente no se puede decir que el promedio de resistencia para una temperatura de 250 grados sea diferente del de la temperatura 225, asi como tampoco que el de 275 grados sea diferente del de 250 grados, sea ha probado que la resistencia promedio a una temperatura de 275 si es mayor que la de temperaturas bajas como 200 y 225, de igual forma, para las temperaturas de 225 y 250 si se tiene una resistencia promedio mayor que para 200 grados

Hay que notar como las concluciones no dan cifras especificas y esto es debido al factor aleatorio que se le agrego 

- Ejemplo **escarabajos** mixto (efectos aleatorios y glm)

$$log(\frac{\pi_{ij}}{1-\pi_{ij}})=\beta_0+\tau_i+\delta_j$$

\(\tau_i=\) indica el efecto del tipo de recolecta (fijo) 

\(\delta_j=\) el efecto de la parcela (aleatorio).

```{r eval=FALSE}
# Modelo utilizado efectos fijos
mod1=glm(cbind(M,H)~tipo+parcela,family="binomial",data=base) # cbind(exito,fracaso)

# Modelo utilizado ejectos aleatorios
mod3=glmer(cbind(M,H)~tipo+(1|parcela),family = "binomial",data = base)
```

- Ejemplo **escuelas** diseños anidados

No se analiza la interacción cuando el diseño es anidado ya que los instructores que están
en una escuela no son los mismos que están en otra escuela.

$$\mu_{ij}= \mu+\alpha_i+\beta_{j(i)}$$

\(\alpha_i=\) efecto de la i-esima escuela

\(\beta_{i(j)}=\) efecto de j-esimo intructor dentro de la i-esima escuela
```{r eval=FALSE}
#De esta forma se indica que el factor instructor está anidado dentro del factor escuela.
mod5=lm(puntaje~escuela+escuela/instructor, data = base)
```

- **H0**

Los puntajes promedio para cada par de instructores dentro de cada escuela son iguales.

- Interpretacion del anova

Una línea que parece una interacción que dice
escuela:instructor, pero que en realidad debería leerse instructor(escuela), es decir, instructor
dentro de escuela.

- Alternativa en escuelas **escuelas**

Cómo se alteran las conclusiones si se considera que hay muchos instructores en cada región y en el
experimento los que participaron fueron una muestra

Para analizar el efecto de instructor cambia la hipótesis. En tal caso \(H0:\sigma_\beta^2=0\) Además
no tendría sentido hacer comparaciones entre instructores a pesar de que se haya demostrado
un efecto del instructor.

```{r eval=FALSE}
#Para probar efecto de instructor
mod2=lmer(puntaje~1+(1|escuela)+(1|instructor1),data=base)
mod22=lmer(puntaje~1+(1|escuela),data=base)
summary(mod2)
anova(mod2,mod22)
```

```{r eval=FALSE}
#Intervalo de confianza
confint(mod2)
```

```{r eval=FALSE}
#Resultado
Computing profile confidence intervals ...
               2.5 %    97.5 %
.sig01      4.374292 15.463474
.sig02      0.000000 11.487301
.sigma      1.643105  5.306366
(Intercept) 7.501444 22.498690
```
**Interpretacion:** El intervalo de confianza para la desviación estándar de los coeficientes de escuela limita con
el cero, lo cual hace que no se rechace la hipótesis nula referente a la igualdad de medias entre
escuelas. Sin embargo, se siguen viendo diferencias entre los instructores dentro de escuelas
pero no interesa comparar los instructores de forma específica.

**Conclusión:** se encontró que la escuela de la Región K obtiene calificaciones promedio más
altas que las otras dos escuelas, pero además dentro de cada escuela, hay diferencias entre los
dos instructores. Del gráfico que se presentó al inicio, se observa que uno de los instructores de
la Región K tiene calificaciones mayores y, aunque su compañero tiene calificaciones más bajas
que las de él, juntos hacen que esta escuela sobresalga. Cabe preguntarse si el desempeño de
estos dos instructores se debe a mejores condiciones en esta escuela, a que los estudiantes que
llegan tienen mayor motivación, o a que realmente estos instructores dan más atención a sus
estudiantes. El desempeño de la escuela no puede desligarse del desempeño de los instructores,
y la causa de los puntajes altos en la Región K no es clara puesto que los estudiantes no fueron
asignados aleatoriamente a las escuelas.


- Ejemplo **cemento** diseños anidados con efecto aleatorio
```{r eval=FALSE}
#Modemos utilizados
mod0=lmer(resist~1+(1|saco1)+(1|lote),data=base) #saco1 es una variable recodificada para el diseño anidado con base$lote:base$saco
mod2=lmer(resist~1+(1|lote:saco)+(1|lote),REML=F,data=base) #Opcion sin confirmar
mod3=lmer(resist~1+(1|lote),REML=F,data=base) #Para probar el efecto del saco
```
- Interpretacion de los intervalos (confint)
```{r eval=FALSE}
Computing profile confidence intervals ...
                 2.5 %    97.5 %
.sig01       2.1579337  4.053589
.sig02       0.0000000  2.946591
.sigma       0.6520234  1.085448
(Intercept) 58.6636504 61.443016
```

**Interpretacion:** En estos resultados, sig01 es la desviación estándar de saco, mientras que sig02 es la
desviación estándar de lote. El intervalo correspondiente a lote tiene como límite inferior
cero, lo cual es una indicación de que esa fuente de variabilidad no es importante.

## Formulas

Para un diseño anidado los efectos del factor anidado dentro de cada nivel del factor superior:
$$\beta_{j(i)}=\mu_{ij}-\mu_i$$

Formula para obterner la estimacion de la varianza del lote apartir de un modelo lm
$$\hat{\sigma^2}_L=\frac{CMLote-CMRes}{n}$$
Probabilidad:
$$\pi=\frac{e^\eta}{1+e^\eta}$$

Propencion:
$$\frac{\pi}{1-\pi}$$

## Funciones/codigos

- Codigo para recodificar una variable en una nueva 

```{r eval=FALSE}
library(dplyr)
base = base %>%mutate(res = case_when(clase=="muertos"~1,TRUE~0))
```
- Intervalos de confianza para un modelo mixto
```{r eval=FALSE}
# En el resultado se debe interpretar sigma como la desviación estándar del error y sigma01 la desviación estándar de lote.
round(confint(profile(mod1)),3)
# En escarabajos 2 era el contraste resultante en suma nula
exp(confint(mod11)*2)
```
**Interpretacion** del intervalo de colorantes: Puesto que el intervalo de 95% de confianza va de 12.2 a 84.1 (no llega al extremo de cero),
se confirma que la fuente de variabilidad de lote a lote no es nula. Sin embargo, ese intervalo
de confianza es muy ancho, lo cual hace dudar de la precisión de la estimación. Se requeriría
un mayor número de lotes para tener una mejor estimación de la varianza de lote a lote, y esto
además produciría una mejor estimación de la varianza del error, ya que se contaría con más
datos en total.

**Interpretacion:** la varianza de parcela a parcela es 0.315, la desviación estándar es 0.561 y su intervalo va
de 0.273 a 1.323.

**Interpretacion:** del intervalo de espectofotometro: Al observar el intervalo de 95% de confianza se tiene que la desviación estándar de los efectos
de interacción está entre 2.07 y 8.6, mientras que la desviación estándar del error está entre
3.1 y 6.3. Es claro que el efecto de interacción tiene una variabilidad no nula.

- Porcentaje de variabilidad
```{r eval=FALSE}
lote=1764     
resi=2451

lote/(resi+lote)
```

**Interpretacion:** 41.8% de la variabilidad es debido a los lote

- Prueba LTR
```{r eval=FALSE}
# con interaccion
mod1=lmer(trigli~maq+(1|dia)+(1|dia:maq),data = base)
dev1=deviance(mod1,REML=FALSE)
summary(mod1)
coef1=7 #1 intercepto y 3 efectos de maquinas 3 componentes aleatorios 
```
```{r eval=FALSE}
# sin interaccion
mod2=lmer(trigli~maq+(1|dia),data = base)
summary(mod2)
dev2=deviance(mod2,REML=FALSE)
coef2=6 #1 intercepto , 3 maquinas y 2 componentes aleatorios
```
```{r eval=FALSE}
# Prueba de razon de verosimulitud a pie
LTR=dev2-dev1
gl=coef1-coef2
#valor p
pchisq(q=LTR,df=gl,lower.tail = F,log.p = F)
```

- Prueba de razón de verosimilitud (LRT) - drop
```{r eval=FALSE}
#Recordar que dro1p es solo para las H0 de efectos fijos / no nos sirve para el de varianzas osea de efectos aleatorios mientras que anova es para aleatorios etc

#para probar H0 en un diseno multinivel (fijos)
drop1(mod1,test = "Chisq")

#para propenciones
drop1(mod1,test = "LRT")

#(quasipoisson) prueba F
drop1(mod2,test = "F")

#binomial negativa
drop1(mod1,test = "LRT")

#para disenos anidados 
anova(mod5)

#para disenos anidados comparando dos modelos/efectos aleatorios
#H0 efecto tipo de recolecta es distinto de cero
anova(mod2,mod3,test="LRT")

```

- Comparaciones con **emmeans**
```{r eval=FALSE}
emmeans(mod1, pairwise~temp|metodo, adjust="bonferroni") #para comparar las temperaturas por metodo
```

```{r eval=FALSE}
emmeans(mod2, pairwise~temp, adjust="bonferroni") #para comparar temperatura
```

- Comparacion de modelos con el metodo de momentos **(anova)**
```{r eval=FALSE}
mod1=glm(cbind(M,H)~tipo+parcela,family="binomial",data=base) #modelo con el efecto que queremos probar 
mod2=glm(cbind(M,H)~parcela,family="binomial",data=base)
anova(mod2,mod1,test="LRT") #modelo sin esa variable
#si se rechaza la H0 la variable si tiene un efecto 
```
- Comparaciones con tukey
```{r eval=FALSE}
#grados de libertad
t=L/ee
#3 numero de contrastes !!!!
ptukey(t*sqrt(2),3,gl,lower.tail = F)
```

- Matriz util para verificar matriz de estructura
```{r eval=FALSE}
#donde 8 es el numero de unidades por trat
data.frame(model.matrix(mod1),base$trat1)[1:8,]
```

- **Cambiar entre suma nula y tratamiento de referencias**
```{r eval=FALSE}
#tratamiento de referencias
options(contrasts=c("contr.treatment","contr.poly"))
#suma nula
options(contrasts=c("contr.sum","contr.poly"))
```

- Estimaciones de los coeficientes para suma nula
```{r eval=FALSE}
coef1=mod1$coefficients;round(c(coef1,-sum(coef1[-1])),3) #lo ultimo es para conseguir tau4
```

- Ejemplo de estimacion de probabilidades
```{r eval=FALSE}
coef=mod1$coef
beta0=coef[1]
taus=coef
taus[1]=0

probabilidades=exp(beta0+taus)/(1+exp(beta0+taus))
names(probabilidades)=c("D0","D200","D400","D800");round(probabilidades,2)
```

- Estimacion de probabilidades con la funcion predic
```{r eval=FALSE}
round(tapply(predict(mod1,type ="response"),base$dosix,mean),4)
```

- Verificar tipo de modelo
```{r eval=FALSE}
contrasts(base$factordiseno)

#ademas se puede utilizar

model.matrix(mod1)
```

- Obtener los efectos
```{r eval=FALSE}
m.es=tapply(base$puntaje,base$escuela,mean)
m=tapply(base$puntaje,list(base$instructor,base$escuela),mean)
in1=m.es-m[1,]
in2=m.es-m[2,]
h=rbind(in1,in2);h
```

- Suma de cuadrados
```{r eval=FALSE}
r=2 #replicas
scres=sum(r*h^2);scres
#h son los efectos
```
- Grados de libertad
```{r eval=FALSE}
gl=(2-1)*3
gl
```
**Interpretacion:** Dentro de cada escuela hay dos instructores diferentes por lo que hay un grado de libertad
para los instructores de cada escuela. Como son 3 escuelas se tiene en total 3 grados de
libertad.

- Cuadrado medio
```{r eval=FALSE}
scres/gl
```
**Interpretacion:** El cuadrado medio de instructor dentro de escuela es 189.2. Esta es una medida de la
variabilidad entre los promedios obtenidos por los instructores de cada escuela.

- **Efectos directamente**
```{r eval=FALSE}
model.tables(aov(mod1))
```

- Obtener las propenciones de cada tratamiento
```{r eval=FALSE}
#vectores individuales con ref

coef=mod1$coefficients
d0=c(1,0,0,0)
d200=c(1,1,0,0)
d400=c(1,0,1,0)
d800=c(1,0,0,1)

#vector de coeficientes

v=cbind(d0,d200,d400,d800); 
v2=t(v)%*%coef

```

```{r eval=FALSE}
#OR de cada tratamiento
OR=exp(v2);round(OR,2)
```

- Comparaciones a pie
```{r eval=FALSE}
#vectores de contrastes

d800_d0=d800-d0
d800_d200=d800-d200
d800_d400=d800-d400
d400_d0=d400-d0
d400_200=d400-d200
d200_d0=d200-d0

h=cbind(d800_d0,d800_d200,d800_d400,d400_d0,d400_200,d200_d0)
L=t(h)%*%coef

#odds ratio
ORR=exp(L);round(ORR,2)
```

- Pruebas de hipótesis para verificar que cada par de tratamientos
```{r eval=FALSE}
#planteo del error
(ee = sqrt(diag(t(h)%*%vcov(mod1)%*%h)))

#obtenemos los estimados de los contrastes o nuestro eta
L=t(h)%*%coef;L

#valor estandarizado del contraste
t=L/ee;t

#obtenemos la probabilidad asociada
p=pnorm(t,lower.tail=F)

#no olvidemos la correccion de bonferroni k= numero de comparaciones
k=6
alfa=0.05/k
p>alfa
```

- Caso para poisson

Debido a que se usa el modelo quasi-Poisson, se debe utilizar la
distribución t en las pruebas. Esta probabilidad debe usar los grados de libertad residuales del modelo. El resultado de la probabilidad debe compararse contra α/6.
 
```{r eval=FALSE}
#error 
ee=sqrt(diag(t(h)%*%vcov(mod2)%*%h))
#valor estandarizado
t=L/ee
#prueba
k=6
gl=nrow(base)-length(coef2)
p=pt(t,gl,lower.tail = F);p
p>0.05/k
```

- Intervalos de 95% de confianza global
```{r eval=FALSE}
#quitamos los no significativos
L2=L[-5,]
L2
ee2=ee[-5]

#valor k (contrastes significativos) en este caso solo 5 son significativas
k=5

#valor qz
qz=qnorm(1-0.05/(2*k))
ic.sup=exp(L2+qz*ee2)
ic.inf=exp(L2-qz*ee2)
round(cbind(ic.inf,ic.sup,ee2),2)
```

- Para limites inferiores con 95% de confianza
```{r eval=FALSE}
#limites inferiores
k=5
#al ser solo un limite ya k no se multiplica por 2
qz=qnorm(1-0.05/k)
L2=L[-5,];ee2=ee[-5]
LIM.INF=exp(L2-qz*ee2);round(LIM.INF,2)
```

- Para limites inferiores ejemplo anidados
```{r eval=FALSE}
gl=nrow(base)-length(coef)
alpha=0.10
qt=qt(1-alpha,gl); LIM=L-qt*ee #cuando son dos hay que dividir el alpha en 2
row.names(LIM)=row.names(p)
round(LIM,1)
```
**Interpretacion:** Con una confianza globla del 95%, se espera que la propencion de daño
para la d800 sea almenos 40% mayor que para la d400, almenos 61% mayor
que para la d200 y cerca de 12 veces la propencion de daño de la d0, por
otra parte la propencion de daño de la d400 es almenos 6 veces la de d0
y la propencion de daño de la d200 es almenos 5 veces la de d0

**interpretacion:** Estas cantidades representan la razón entre cada par de medias, por ejemplo, la media de miel es un 19% mayor que la media de sirope, la media de miel es 6.7 veces la media de vinagre, etc. Se nota que las que más se diferencian son miel y vinagre, así como sirope y vinagre.

**Interpretacion inferior diseños anidados:** En la Región K, el puntaje promedio del instructor 1 es al menos 10.7 puntos mayor que el del instructor 2, en la Región D, el puntaje promedio del instructor 2 es al menos 7.7 puntos
mayor que el del instructor 1, y en la Región Central, el puntaje promedio del instructor 1 es
al menos 11.2 puntos mayor que el del instructor 2. Todo esto se puede asegurar con 90% de
confianza.

**Intepretacion intervalo al 90% disenos anidados escuelas:** Con 90% de confianza global se puede esperar que el puntaje promedio de la Región K esté al menos 1.86 puntos sobre el de la Región D, y al menos 5.11 puntos sobre el de la Región
Central.

- valores ajustados con la función predict
```{r eval=FALSE}
tapply(predict(mod1,type = "response"),base$trat1,mean)
fit=predict(mod1,type = "response")
```

- Calculo de los residuales de person y el parametro de dispercion phi \((\phi)\)a pie
```{r eval=FALSE}
res=residuals(mod1,type = "pearson")
phi=sum(res^2)/(nrow(base)-length(coef1));phi
```
- Parametro de dispercion usando summary(mod)$disp
```{r eval=FALSE}
#funciona solo en modelos quasipoisson o binomial negativa
summary(mod1)$disp
```

**interpretacion:** Se obtiene un parámetro de dispersión ϕ = 6.1, el cual es mucho mayor que 1, por lo que se comprueba la sospecha de que existe sobredispersión, por lo tanto, no se cumple el supuesto que dice que la media condicional es igual que la variancia condicional.

- Prueba formal 

cuya hipótesis nula es equidispersión, es decir, que se cumple el supuesto básico de la distribución de Poisson que es \(V[Y|X]=E[Y|X]\). Para esto se usa la función dispersiontest en la librería AER. Esta función requiere de un modelo Poisson ajustado con glm y una especificación de una hipótesis alternativa mediante el parámetro trafo, el cual corresponde a 1 para la quasi-Poisson y 2 para la binomial negativa. Además se usa el parámetro alternative="greater" para indicar sobredispersión, sin embargo, no es necesario indicarlo pues éste es el default. En el caso de subdispersión se usa alternative="less".

```{r eval=FALSE}
library(AER)

#quasi-Poisson
dispersiontest(mod1,trafo = 1)

#binomial negativa
dispersiontest(mod1,trafo = 2)

```
- Criterios para las H0 de las pruebas trafo

*si no se rechaza ninguna sigo con una poisson*

*si se rechaza la primera y la seguda no uso quasi-Poisson*

*si se rechaza la segunda y no la primera uso binomial negativa*

*si se rechanzan las dos no hay criterio*

*si quisieramos cuasipoisson*

- Estimacion la variancia condicional en cada tratamiento

Con el modelo quasi-Poisson y con binomial negativa. Compararacion con
las variancias observadas para ver cuál las ajusta mejor.

para la quasi-poisson $\sigma^2_j=\phi\lambda_j$ para la binomial
negativa $\lambda_j+\frac{\lambda^2_j}{\theta}$

```{r eval=FALSE}
#observadas
var.obser=tapply(base$conteo,base$trat1,var)
media=tapply(base$conteo,base$trat1,mean)


#var. binomial
phi=summary(mod2)$disp
var.bino=phi*media

#var binomial
theta=summary(mod3)$theta
alpha=1/theta
var.quasi=media+alpha*(media^2)

round(cbind(var.obser,var.bino,var.quasi),3)
```


## Topicos de interes

La prueba para evaluar el efecto del factor de diseño compara la
verosimilitud de dos modelos: uno con el factor de diseño y otro sin él.

La prueba de la razón de verosimilitud (LRT) que compara modelos
mediante el logaritmo de la razón de verosimilitudes y luego contrasta
el resultado con una distribución Chi-cuadrado.

Los grados de libertad en este caso se calculan restando los grados de
libertad del modelo con el factor continuo a los grados de libertad del
modelo con el factor discreto.

- Concepto de Propencion

La propensión es el cociente de la probabilidad de éxito a la
probabilidad de fracaso, utilizada para medir la intensidad de la
ocurrencia del evento. Una propensión de 1 indica equiprobabilidad de
éxito y fracaso. Menos de 1 indica más (intencidad de) fracasos, más de
1 indica más (intensidad de) éxitos.

$$odds_i=\frac{\pi_i}{1-\pi_i}=e^{\beta_0+\alpha_i}=e^{\eta_i}$$

Una forma de comparar estas dos propensiones es mediante su razón. Esta
medida es muy conocida por sus siglas en inglés OR (odds ratio). El OR
al comparar el j-ésimo tratamiento respecto al k-ésimo tratamiento se
puede obtener del modelo como:
$$OR(j:k)=\frac{odds_j}{odds_k}=e^{\alpha_j-\alpha_k}$$

En el caso particular en que el factor de diseño tiene solo dos niveles
y se usa el modelo de suma nula, la restricción implica que α2 = − α1 ,
por lo que el OR se simplifica a:

$$OR(1:2)==e^{2\alpha_1}$$


### Generalidades para el caso continuo en propenciones

- Probabilidad de daño para una dosis de 300 g/l
```{r eval=FALSE}
coef=mod2$coefficients
eta=c(1,300)%*%coef
prop=exp(eta)/(1+exp(eta));prop
```
- Probabilidad de daño para una dosis de 300 g/l con la funcion predict
```{r eval=FALSE}
predict(mod2,data.frame(dosis=300),type = "response")
```

- Valor relevante para fines de interpretacion
```{r eval=FALSE}
exp(coef%*%c(0,200))
```

**Interpretacion:** por cada aumento de 200 ml en la dosis se espera que el daño sea mas propenso en un 75%

- Intervalo de confianza para dosis de 200
```{r eval=FALSE}
round(exp(confint(mod2,level = 0.95)*200),3)
```

**Interpretacion:** Se obtiene que al aumentar la dosis en 200 g/l, se puede esperar con
95% de confianza que la propensión de daño aumente por un factor que
está entre el 1,60 y 1,94. Aunque aquí no hay un delta, como se trata de
aumentos porcentuales, se puede ver que ya un aumento de 60% en la
propensión es cosiderable y por tanto se nota que aumentos de este
tamaño en la dosis (200 g/l) van a provocar aumentos relevantes en la
probabilidad de daño.*

- Evaluar interacción entre dosis y genotipo
```{r eval=FALSE}
drop1(mod4,test = "LRT")
```

- Ecuaciones estimadas para el modelo

Para genotipo R

$log(\frac{p}{1-p})=-1.438+0.002D$

Para genotipo S

$log(\frac{p}{1-p})=-1.424+0.003D$

**Calculo e interpretacion de los OR**

para genotipo R: d y d+100
```{r eval=FALSE}
#prueba
c(1,d+100,0,(d+100)*0)-c(1,d,0,d*0)= c(0,200,0,0)
c(1,d+100,0,(d+100)*1)-c(1,d,0,d*1)= c(0,200,0,200)

R=c(0,200,0,0)
S=c(0,200,0,200)

R.OR=exp(R%*%mod4$coefficients);R.OR
S.OR=exp(S%*%mod4$coefficients);S.OR
```

**Interpretacion:** Por lo tanto, se nota que el impacto de un aumento de 200 g/l en la
dosis es mayor para las plantas de genotipo S puesto que el OR es 2,05
(aumento por un factor 2,05 en la propensión de daño), mientras que para
las plantas de genotipo R el OR es 1,53 (aumento de 53% en la propensión
de daño).

- Intervalos de confianza 95% para cada genotipo 
```{r eval=FALSE}
#contrastes de d y d+100

R=c(0,200,0,0)
S=c(0,200,0,200)

eta=mod4$coefficients

h=cbind(R,S)
L=t(h)%*%eta

ee4=sqrt(diag(t(h)%*%vcov(mod4)%*%h))

#correccion 
k=2

qz=qnorm(1-0.05/(2*k))

ic.sup=exp(L+qz*ee4)
ic.inf=exp(L-qz*ee4)

round(cbind(ic.inf,ic.sup,ee4),2)
```

**Interpretacion:** Para el genotipo R, cuando se incrementa la dosis en 200 g/l, la
propensión aumenta entre un 32% y un 78%, mientras que para el genotipo
S aumenta por un factor entre 1,75 y 2,4.
