{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNbLKHMCoSkuiAvs/dXiUsK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Carga y filtrado de imagenes"],"metadata":{"id":"bsLszP7LnSvo"}},{"cell_type":"markdown","source":["Pasos generales:\n","* Subir el Archivo de datos a su drive (Si es necesario)\n","* Cambiar la direccion a su direccion en su drive (Si es necesario)"],"metadata":{"id":"UNYZMgy9nWmJ"}},{"cell_type":"code","source":["import os\n","import zipfile\n","\n","# Definir el nombre del archivo ZIP y la ruta en Google Drive\n","zip_file = \"/content/drive/MyDrive/Ciencia de datos/Proyecto/Datosp.zip\"\n","\n","# Definir el directorio de destino donde se descomprimirá el archivo\n","destination_dir = \"/content/drive/MyDrive/Ciencia de datos/Proyecto\"\n","\n","# Descomprimir el archivo ZIP\n","with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n","    zip_ref.extractall(destination_dir)\n","\n","# Verificar que el archivo se haya descomprimido correctamente\n","print(os.listdir(destination_dir))"],"metadata":{"id":"xSbMlE_qnXKw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Creamos una copia de seguridad del archivo para evitar futuros problemas"],"metadata":{"id":"o0kVj44Nne6R"}},{"cell_type":"code","source":["import shutil\n","import os\n","\n","# Definir la ruta del directorio original\n","original_dir = \"/content/drive/MyDrive/Ciencia de datos/Proyecto/vehicle_data\"\n","\n","# Definir la nueva ruta con el nombre cambiado\n","new_dir = \"/content/drive/MyDrive/Ciencia de datos/Proyecto/vehicle_data_original\"\n","\n","# Copiar el directorio y renombrarlo\n","shutil.copytree(original_dir, new_dir) # Use shutil.copytree() for directories\n","\n","# Verificar que el directorio se haya copiado correctamente\n","if os.path.exists(new_dir):\n","    print(f\"Directorio copiado y renombrado a: {new_dir}\")\n","else:\n","    print(\"La copia no se realizó correctamente.\")"],"metadata":{"id":"xgzRCf2SnffG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Algunas imágenes del archivo original (vehiculos_data) parecen estar dañadas o en un formato no compatible, lo que generaba errores. Por esta razón, se procedió a eliminar las imágenes que causaban dichos problemas mediante la siguiente funcion."],"metadata":{"id":"fBGgqEp6nm0-"}},{"cell_type":"markdown","source":["* Funcion para filtar las imagenes que producen errores"],"metadata":{"id":"mjy7sNranqmX"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","def load_and_filter_image(image_path):\n","    try:\n","        # Leer el archivo de imagen\n","        img = tf.io.read_file(image_path)\n","        # Decodificar la imagen a un formato usable\n","        img = tf.image.decode_image(img)\n","        return img\n","    except tf.errors.InvalidArgumentError as e:\n","        # Manejar errores de carga y decodificación\n","        print(f\"Error al cargar la imagen: {image_path}\")\n","        return None"],"metadata":{"id":"jApEkCP7nrMh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Aplicando funcion para resolver los errores (Este codigo solo funciona una vez, no correra amenos de que la base presente los problemas iniciales)"],"metadata":{"id":"gFKeK6OHnznX"}},{"cell_type":"code","source":["# Definir el directorio raíz que contiene las imágenes\n","root_directory = \"/content/drive/MyDrive/Ciencia de datos/Proyecto/vehicle_data\"\n","\n","# Recorrer todos los archivos en el directorio y subdirectorios\n","for root, dirs, files in os.walk(root_directory):\n","    for filename in files:\n","        file_path = os.path.join(root, filename)\n","        # Filtrar solo archivos de imagen con extensiones válidas\n","        if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp')):\n","            # Intentar cargar la imagen\n","            image = load_and_filter_image(file_path)\n","            # Si la imagen no se pudo cargar, eliminar el archivo\n","            if image is None:\n","                os.remove(file_path)\n","                print(f\"Archivo eliminado: {file_path}\")"],"metadata":{"id":"Ttu4PIXzn4Uo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Conteo de archivos para verificar cuantos fueron eliminados, etc."],"metadata":{"id":"pSNb4OO_oEx0"}},{"cell_type":"code","source":["import os\n","\n","# Especificar la ruta de la carpeta original (antes de eliminar archivos)\n","root_directory = \"/content/drive/MyDrive/Ciencia de datos/Proyecto/vehicle_data\"\n","folder_path = \"/content/drive/MyDrive/Ciencia de datos/Proyecto/vehicle_data_original\"\n","\n","# Contar recursivamente todos los archivos y carpetas en la carpeta principal\n","element_count = 0\n","for root, dirs, files in os.walk(folder_path):\n","    element_count += len(dirs) + len(files)\n","\n","# Mostrar el número total de elementos (archivos y carpetas) antes de eliminar\n","print(f\"Número total de elementos en la carpeta '{folder_path}' y sus subdirectorios: {element_count}\")\n","\n","# Contar recursivamente todos los archivos y carpetas en la carpeta filtrada\n","element_count2 = 0\n","for root, dirs, files in os.walk(root_directory):\n","    element_count2 += len(dirs) + len(files)\n","\n","# Mostrar el número total de elementos después de filtrar\n","print(f\"Número total de elementos en la carpeta '{root_directory}' y sus subdirectorios: {element_count2}\")\n","\n","# Cálculos de archivos eliminados\n","sinfiltrar = element_count\n","filtrados = element_count2\n","eliminados = sinfiltrar - filtrados\n","\n","# Mostrar resultados finales\n","print(f\"Número total de archivos eliminados que provocaban un error: {eliminados}\")"],"metadata":{"id":"lGJEc_lIoFVu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Listo este es el proceso incial mediante el cual se se cargaron los datos, se descomprimieron, se creo una copia de seguridad, y se filtraron los datos que producian algun tipo de error ala hora de subir los datos para el modelo."],"metadata":{"id":"B9QUEkzFoJGV"}},{"cell_type":"markdown","source":["## Carga de datos y caracteristicas"],"metadata":{"id":"-TNn6pkhoYL0"}},{"cell_type":"markdown","source":["* Cargar los datos al modelo\n","\n","Asegurarse de que esta conectado al Drive para que no precenten errores en esta primera parte"],"metadata":{"id":"Mbj_IlL4ocI0"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","\n","# Especificar el directorio que contiene las imágenes\n","directory = \"/content/drive/MyDrive/Ciencia de datos/Proyecto/vehicle_data\"\n","\n","# Cargar los datos como root_directory\n","data = keras.utils.image_dataset_from_directory(\n","    directory,               # Directorio que contiene las imágenes\n","    labels=\"inferred\",       # Inferir las etiquetas de los nombres de las carpetas\n","    label_mode=\"int\",        # Usar enteros como modo de etiquetas\n","    color_mode=\"rgb\",        # Cargar imágenes en modo RGB\n","    batch_size=6,            # Tamaño del lote\n","    shuffle=True,            # Aleatorizar los datos\n","    seed=1234                # Semilla para la aleatorización\n",")"],"metadata":{"id":"_HcCTGtIoaZH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Caracteristicas del conjunto de datos"],"metadata":{"id":"G2uq2S42oknE"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","# Mostrar las características de las clases en el conjunto de datos\n","print(data.class_names)\n","\n","# Inicializar un diccionario para contar observaciones por categoría\n","observations_per_category = {class_name: 0 for class_name in data.class_names}\n","\n","# Contar el número de observaciones por categoría\n","for images, labels in data:\n","    labels = labels.numpy()  # Convertir etiquetas a un formato NumPy\n","    # Contar etiquetas únicas y sus ocurrencias\n","    unique, counts = np.unique(labels, return_counts=True)\n","\n","    # Actualizar el diccionario con los conteos\n","    for idx, count in zip(unique, counts):\n","        observations_per_category[data.class_names[idx]] += count\n","\n","# Imprimir el número de categorías en el conjunto de datos\n","print(f\"Número de categorías: {len(np.unique(data.class_names))}\")\n","# Mostrar el número de observaciones por categoría\n","print(\"Número de observaciones por categoría:\")\n","for class_name, count in observations_per_category.items():\n","    print(f\"  {class_name}: {count}\")"],"metadata":{"id":"dxqp8eWLolEy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Ejemplos por categoria"],"metadata":{"id":"9ShlVsZEoqVT"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Configurar la figura para visualizar las imágenes\n","plt.figure(figsize=(10, 10))\n","\n","# Inicializar un conjunto para seguir las etiquetas que ya se han mostrado\n","seen_labels = set()\n","\n","# Inicializar un contador de imágenes\n","image_count = 0\n","\n","# Iterar sobre el conjunto de datos para encontrar una imagen por categoría\n","for images, labels in data:\n","    for j in range(images.shape[0]):\n","        label = labels[j].numpy()  # Obtener la etiqueta de la imagen\n","\n","        # Si la etiqueta ya ha sido vista, continuar\n","        if label in seen_labels:\n","            continue\n","\n","        # Añadir la etiqueta al conjunto de etiquetas vistas\n","        seen_labels.add(label)\n","\n","        # Obtener una sola imagen del lote\n","        single_image = images[j].numpy().astype(\"uint8\")  # Convertir la imagen a uint8\n","\n","        # Ajustar la posición del subplot, incrementando el contador\n","        plt.subplot(5, 4, image_count + 1)\n","        plt.xticks([])\n","        plt.yticks([])\n","        plt.grid(False)\n","        plt.imshow(single_image)  # Mostrar la imagen\n","        plt.xlabel(data.class_names[label])  # Etiqueta correspondiente\n","\n","        # Incrementar el contador de imágenes\n","        image_count += 1\n","\n","        # Si se han mostrado 20 imágenes, salir del bucle\n","        if image_count >= 20:\n","            break\n","    if image_count >= 20:\n","        break  # Salir del bucle principal si ya se mostraron 20 imágenes\n","\n","plt.show()"],"metadata":{"id":"PfruyAGmoq19"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Modelos"],"metadata":{"id":"6pdgsWHfozP7"}},{"cell_type":"markdown","source":["## Modelo MLP"],"metadata":{"id":"T9Oq27L6o86a"}},{"cell_type":"markdown","source":["* Carga de datos"],"metadata":{"id":"hnna5cFtpEui"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","\n","# Especificar el directorio que contiene las imágenes\n","#directory = \"/content/drive/MyDrive/Ciencia de datos/Proyecto/vehicle_data\"\n","directory = \"C:/Users/cesar/OneDrive/Escritorio/vehicle_data\"\n","\n","# Cargar los datos como root_directory\n","data = keras.utils.image_dataset_from_directory(\n","    directory,               # Directorio que contiene las imágenes\n","    labels=\"inferred\",       # Inferir las etiquetas de los nombres de las carpetas\n","    label_mode=\"int\",        # Usar enteros como modo de etiquetas\n","    color_mode=\"rgb\",        # Cargar imágenes en modo RGB\n","    batch_size=6,            # Tamaño del lote\n","    shuffle=True,            # Aleatorizar los datos\n","    seed=1234                # Semilla para la aleatorización\n",")\n"],"metadata":{"id":"b7DBUsyVpFYO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Division de la base y transformacion de los datos"],"metadata":{"id":"0DW6hzLGpIwl"}},{"cell_type":"code","source":["# Importar las librerías necesarias\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","# Convertir datos a numpy arrays\n","# (esto puede variar dependiendo de cómo cargaste los datos)\n","images, labels = [], []  # Listas para almacenar imágenes y etiquetas\n","\n","# Recorrer los lotes de datos y agregar a las listas\n","for image_batch, label_batch in data:\n","    images.extend(image_batch.numpy())  # Convertir y agregar imágenes\n","    labels.extend(label_batch.numpy())   # Convertir y agregar etiquetas\n","\n","# Convertir listas a arrays de numpy\n","images = np.array(images)\n","labels = np.array(labels)\n","\n","# Estratificación y división de datos\n","# X contendrá las imágenes y y contendrá las etiquetas\n","X_train, X_test, y_train, y_test = train_test_split(\n","    images, labels, test_size=0.3, random_state=42, stratify=labels\n",")\n","\n","# Dividir el conjunto de prueba en validación y prueba\n","X_val, X_test, y_val, y_test = train_test_split(\n","    X_test, y_test, test_size=0.5, random_state=42, stratify=y_test\n",")\n","\n","# Mostrar la cantidad de datos en cada conjunto\n","print(len(y_train), len(y_val), len(y_test))\n","\n","# Normalizar los píxeles entre 0 y 1\n","X_train = X_train.astype('float32') / 255.0\n","X_val = X_val.astype('float32') / 255.0\n","X_test = X_test.astype('float32') / 255.0\n","\n","# Codificación one-hot para las etiquetas\n","num_classes = len(data.class_names)  # Número de clases\n","y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n","y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n","y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n","\n","# Aplanar las imágenes en 1D\n","X_train = X_train.reshape(X_train.shape[0], -1)\n","X_val = X_val.reshape(X_val.shape[0], -1)\n","X_test = X_test.reshape(X_test.shape[0], -1)"],"metadata":{"id":"CTKUnPxHpKi9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Verificar conteos por division, etc."],"metadata":{"id":"U-HL5KnEpPPU"}},{"cell_type":"code","source":["# Imprimir las formas de los conjuntos de datos\n","print(\"Forma del conjunto de entrenamiento:\", X_train.shape)\n","print(\"Forma del conjunto de validación:\", X_val.shape)\n","\n","# Mostrar los nombres de las clases en el conjunto de datos\n","print(\"Nombres de las clases:\", data.class_names)\n","print(\"Número de categorías:\", len(data.class_names))\n","\n","# Imprimir los valores mínimo y máximo en el conjunto de entrenamiento\n","print(\"Valor mínimo en X_train:\", X_train.min())\n","print(\"Valor máximo en X_train:\", X_train.max())"],"metadata":{"id":"hishlWu6pRWC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Entrenamiento y modelo"],"metadata":{"id":"89Gd6NKMpVpE"}},{"cell_type":"code","source":["# Importar las librerías necesarias\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers, regularizers\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Definir el modelo secuencial\n","model = keras.models.Sequential()\n","\n","# Añadir capas densas con regularización L2\n","model.add(layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(X_train.shape[1],)))  # Capa de entrada\n","model.add(layers.Dense(144, activation='relu', kernel_regularizer=regularizers.l2(0.001)))  # Capa oculta\n","model.add(layers.Dense(81, activation='relu', kernel_regularizer=regularizers.l2(0.001)))  # Otra capa oculta\n","model.add(layers.Dense(49, activation='relu', kernel_regularizer=regularizers.l2(0.001)))  # Capa oculta más pequeña\n","\n","# Capa de salida\n","model.add(layers.Dense(num_classes, activation='softmax'))  # Usar num_classes para el número de salidas\n","\n","# Definir el optimizador\n","optimizer = Adam(learning_rate=0.0001)\n","\n","# Compilar el modelo\n","model.compile(optimizer=optimizer,  # Optimizador Adam\n","              loss='categorical_crossentropy',  # Función de pérdida para clasificación\n","              metrics=['accuracy'])  # Métrica a seguir\n","\n","# Definir el callback de EarlyStopping\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',  # Métrica a monitorear\n","    patience=10,  # Número de épocas a esperar sin mejora\n","    restore_best_weights=True  # Restaurar los mejores pesos al final\n",")\n","\n","# Entrenar el modelo\n","history = model.fit(X_train, y_train,  # Datos de entrenamiento\n","                    epochs=100,  # Número máximo de épocas\n","                    batch_size=32,  # Tamaño del lote\n","                    validation_data=(X_val, y_val),  # Datos de validación\n","                    callbacks=[early_stopping])  # Callback de early stopping"],"metadata":{"id":"Hw8htJ9JpW76"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Evaluacion del modelo"],"metadata":{"id":"FcuORjaKpexN"}},{"cell_type":"code","source":["basic_model_eval = model.evaluate(X_test, y_test)\n","print(f\"Modelo básico: error y accuracy {basic_model_eval}\")"],"metadata":{"id":"-iU7MQLxpfOB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Guardar el modelo"],"metadata":{"id":"DgmgYJzHpheF"}},{"cell_type":"code","source":["# Guardar\n","#model.save('model.h5')\n","# Volver a cargar en el ambiente un modelo guardado\n","#from tensorflow.keras.models import load_model\n","#model = load_model('model.h5')"],"metadata":{"id":"9RysWt2FpkAj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Evaluacion grafica"],"metadata":{"id":"v4HSoHUcpnoV"}},{"cell_type":"code","source":["# Importar las librerías necesarias\n","import matplotlib.pyplot as plt  # Para graficar\n","import tensorflow as tf          # Para manejar el historial del entrenamiento\n","\n","# Acceder a la precisión de entrenamiento y validación desde el historial\n","train_accuracy = history.history['accuracy']    # Precisión de entrenamiento\n","val_accuracy = history.history['val_accuracy']  # Precisión de validación\n","\n","# Acceder a la pérdida de entrenamiento y validación desde el historial\n","train_loss = history.history['loss']         # Pérdida de entrenamiento\n","val_loss = history.history['val_loss']       # Pérdida de validación\n","\n","# Configuración de la figura con 1 fila y 2 columnas\n","fig, axs = plt.subplots(1, 2, figsize=(16, 6))  # Ajusta el tamaño según lo necesites\n","\n","# Graficar precisión de entrenamiento y validación\n","axs[0].plot(train_accuracy, label='Entrenamiento', color=\"blue\")    # Precisión de entrenamiento\n","axs[0].plot(val_accuracy, label='Validación', color=\"red\")          # Precisión de validación\n","axs[0].set_title('Accuracy de entrenamiento por epoch')  # Título del gráfico\n","axs[0].set_xlabel('Epoch')                               # Etiqueta del eje X\n","axs[0].set_ylabel('Precisión')                           # Etiqueta del eje Y\n","axs[0].set_ylim(0, 1)\n","axs[0].legend()                                          # Mostrar la leyenda\n","axs[0].grid(True)                                        # Activar la cuadrícula\n","\n","# Graficar pérdida de entrenamiento y validación\n","axs[1].plot(train_loss, label='Entrenamiento', color=\"blue\")    # Pérdida de entrenamiento\n","axs[1].plot(val_loss, label='Validación', color=\"red\")          # Pérdida de validación\n","axs[1].set_title('Error de entrenamiento por epoch')   # Título del gráfico\n","axs[1].set_xlabel('Epoch')                             # Etiqueta del eje X\n","axs[1].set_ylabel('Error')                             # Etiqueta del eje Y\n","axs[1].legend()                                        # Mostrar la leyenda\n","axs[1].grid(True)                                      # Activar la cuadrícula\n","\n","plt.tight_layout()                                     # Ajustar el diseño para evitar solapamientos\n","plt.show()                                             # Mostrar los gráficos"],"metadata":{"id":"NPxvTgNApuCb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Mostrar resultados de imágenes y sus clasificaciones"],"metadata":{"id":"3EBsA4WJpxXj"}},{"cell_type":"code","source":["# Importar las librerías necesarias\n","import numpy as np           # Para operaciones numéricas y manipulación de arrays\n","import matplotlib.pyplot as plt  # Para visualización de imágenes\n","\n","# Mostrar 10 imágenes con sus clasificaciones reales y predichas\n","n = 10  # Número de imágenes a mostrar\n","fig, ax = plt.subplots(1, n, figsize=(9, 9))\n","\n","for i in range(n):\n","    # Obtener la clasificación real y la predicción del modelo\n","    real = np.argmax(y_test[i])  # Clasificación real de la imagen\n","    prediction = model.predict(X_test[i].reshape(1, -1))  # Predicción del modelo\n","    prediction = np.argmax(prediction)  # Obtener el índice de la clase predicha\n","\n","    # Calcular las dimensiones correctas de la imagen\n","    image_size = int(np.sqrt(X_test[i].shape[0] / 3))  # Suponiendo que las imágenes son cuadradas y tienen 3 canales de color\n","\n","    # Reconfigurar los datos de la imagen con el tamaño calculado\n","    ax[i].imshow(X_test[i].reshape(image_size, image_size, 3))  # Mostrar la imagen\n","    ax[i].axis(\"off\")  # Ocultar los ejes\n","    ax[i].set_title(f\"Real: {data.class_names[real]}, \\n Clasificado: {data.class_names[prediction]}\", fontsize=5)  # Título con las clasificaciones\n","\n","plt.show()  # Mostrar la figura con las imágenes"],"metadata":{"id":"vuLTRDZjpyCn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Matriz de confucion"],"metadata":{"id":"j9Tsjmtop2Ge"}},{"cell_type":"code","source":["# Importar las librerías necesarias\n","import numpy as np                         # Para operaciones numéricas y manipulación de arrays\n","from sklearn.metrics import confusion_matrix  # Para generar la matriz de confusión\n","import seaborn as sns                      # Para visualizar la matriz de confusión\n","import matplotlib.pyplot as plt            # Para visualización de gráficos\n","\n","# Calcular las clasificaciones reales y predichas\n","reales = np.argmax(y_test, axis=1)  # Clasificaciones reales de las imágenes\n","predichos = np.argmax(model.predict(X_test), axis=1)  # Predicciones del modelo\n","num_clases = len(data.class_names)  # Número de clases (asegúrate de que coincida)\n","\n","# Generar la matriz de confusión\n","conf_matrix = confusion_matrix(reales, predichos)\n","\n","# Graficar la matriz de confusión usando seaborn\n","plt.figure(figsize=(12, 12))\n","sns.heatmap(\n","    conf_matrix,\n","    annot=False,                     # No anotar los valores en la matriz\n","    fmt='d',                         # Formato de anotación\n","    cmap='Blues',                    # Colormap para la visualización\n","    xticklabels=data.class_names,    # Etiquetas para el eje X\n","    yticklabels=data.class_names     # Etiquetas para el eje Y\n",")\n","\n","# Etiquetas y título\n","plt.xlabel('Predicho')              # Etiqueta del eje X\n","plt.ylabel('Real')                  # Etiqueta del eje Y\n","plt.title('Matriz de confusión')    # Título de la gráfica\n","plt.show()"],"metadata":{"id":"w6V8LxD9p2nB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Metricas de precision"],"metadata":{"id":"EVEUhrGQp80h"}},{"cell_type":"code","source":["from sklearn.metrics import recall_score, f1_score\n","import numpy as np\n","# Calcular las clasificaciones reales y predichas\n","reales = np.argmax(y_test, axis=1)  # Clasificaciones reales de las imágenes\n","predichos = np.argmax(model.predict(X_test), axis=1)  # Predicciones del modelo\n","\n","# Calcular recall y F1 score de forma micro y macro\n","recall_micro = recall_score(reales, predichos, average='micro')\n","f1_micro = f1_score(reales, predichos, average='micro')\n","\n","recall_macro = recall_score(reales, predichos, average='macro')\n","f1_macro = f1_score(reales, predichos, average='macro')\n","\n","# Mostrar los resultados\n","print(f\"Recall Micro: {recall_micro:.4f}\")\n","print(f\"F1 Score Micro: {f1_micro:.4f}\")\n","print(f\"Recall Macro: {recall_macro:.4f}\")\n","print(f\"F1 Score Macro: {f1_macro:.4f}\")"],"metadata":{"id":"3-YgVg5ip8Dx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Modelo de redes convolucionales"],"metadata":{"id":"P-4UyrRPqEze"}},{"cell_type":"markdown","source":["* Carga de datos"],"metadata":{"id":"k7wC4JKtqHV2"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","\n","# Especificar el directorio que contiene las imágenes\n","#directory = \"/content/drive/MyDrive/Ciencia de datos/Proyecto/vehicle_data\"\n","directory = \"C:/Users/cesar/OneDrive/Escritorio/vehicle_data\"\n","\n","# Cargar los datos como root_directory\n","data = keras.utils.image_dataset_from_directory(\n","    directory,               # Directorio que contiene las imágenes\n","    labels=\"inferred\",       # Inferir las etiquetas de los nombres de las carpetas\n","    label_mode=\"int\",        # Usar enteros como modo de etiquetas\n","    color_mode=\"rgb\",        # Cargar imágenes en modo RGB\n","    batch_size=6,            # Tamaño del lote\n","    shuffle=True,            # Aleatorizar los datos\n","    seed=1234                # Semilla para la aleatorización\n",")\n"],"metadata":{"id":"ZHVI-2yDqFXo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Division de la base y transformacion de los datos"],"metadata":{"id":"dgzs-cDeqKme"}},{"cell_type":"code","source":["# Importar las librerías necesarias\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","# Convertir datos a numpy arrays\n","# (esto puede variar dependiendo de cómo cargaste los datos)\n","images, labels = [], []  # Listas para almacenar imágenes y etiquetas\n","\n","# Recorrer los lotes de datos y agregar a las listas\n","for image_batch, label_batch in data:\n","    images.extend(image_batch.numpy())  # Convertir y agregar imágenes\n","    labels.extend(label_batch.numpy())   # Convertir y agregar etiquetas\n","\n","# Convertir listas a arrays de numpy\n","images = np.array(images)\n","labels = np.array(labels)\n","\n","# Estratificación y división de datos\n","# X contendrá las imágenes y y contendrá las etiquetas\n","X_train, X_test, y_train, y_test = train_test_split(\n","    images, labels, test_size=0.3, random_state=42, stratify=labels\n",")\n","\n","# Dividir el conjunto de prueba en validación y prueba\n","X_val, X_test, y_val, y_test = train_test_split(\n","    X_test, y_test, test_size=0.5, random_state=42, stratify=y_test\n",")\n","\n","# Mostrar la cantidad de datos en cada conjunto\n","print(len(y_train), len(y_val), len(y_test))\n","\n","# Normalizar los píxeles entre 0 y 1\n","X_train = X_train.astype('float32') / 255.0\n","X_val = X_val.astype('float32') / 255.0\n","X_test = X_test.astype('float32') / 255.0\n","\n","# Codificación one-hot para las etiquetas\n","num_classes = len(data.class_names)  # Número de clases\n","y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n","y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n","y_test = tf.keras.utils.to_categorical(y_test, num_classes)"],"metadata":{"id":"LomMdBEDqMjG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Verificar conteos por division, etc."],"metadata":{"id":"Xj2DW26nqPzy"}},{"cell_type":"code","source":["# Imprimir las formas de los conjuntos de datos\n","print(\"Forma del conjunto de entrenamiento:\", X_train.shape)\n","print(\"Forma del conjunto de validación:\", X_val.shape)\n","\n","# Mostrar los nombres de las clases en el conjunto de datos\n","print(\"Nombres de las clases:\", data.class_names)\n","print(\"Número de categorías:\", len(data.class_names))\n","\n","# Imprimir los valores mínimo y máximo en el conjunto de entrenamiento\n","print(\"Valor mínimo en X_train:\", X_train.min())\n","print(\"Valor máximo en X_train:\", X_train.max())\n","# Numero de clases como variable\n","k = 20\n","X_train.shape"],"metadata":{"id":"n-i6dhqEqRua"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Modelo y entrenamiento"],"metadata":{"id":"KF-eVTCQqXJo"}},{"cell_type":"code","source":["# Importar TensorFlow y Keras\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","\n","# Crear modelo secuencial\n","model = models.Sequential()\n","\n","# Capa Conv2D: 32 filtros 3x3, activación ReLU,\n","model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","\n","# Capa Conv2D: 64 filtros 3x3, activación ReLU\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","\n","# Capa Conv2D: 64 filtros 3x3, activación ReLU\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.Flatten())\n","\n","# Capa densa: 64 unidades, activación ReLU\n","model.add(layers.Dense(64, activation='relu'))\n","\n","# Capa de salida: 'k' clases, activación softmax\n","model.add(layers.Dense(k, activation='softmax'))\n","\n","# Mostrar resumen del modelo\n","model.summary()\n","\n","# Compilar el modelo con Adam y una tasa de aprendizaje reducida\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Early Stopping: detener el entrenamiento si no mejora después de 10 épocas\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"],"metadata":{"id":"dz1abzFDqYxq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Aumentacion de datos"],"metadata":{"id":"3iOzYmbWqebQ"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Se crea una instancia de \"image data generator\" con los distintos tipos de aumentación que se quieran\n","datagen = ImageDataGenerator(\n","    rotation_range=15,          # Random rotation\n","    width_shift_range=0.1,      # Random horizontal shift\n","    height_shift_range=0.1,     # Random vertical shift\n","    horizontal_flip=True,       # Random horizontal flip\n","    zoom_range=0.1              # Random zoom\n",")\n","\n","# Se ajusta el generador a los datos de entrenamiento\n","datagen.fit(X_train)\n"],"metadata":{"id":"kTlxgszgqg5_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Entrenamiento"],"metadata":{"id":"drrB8DQ-qjRw"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.optimizers import Adam\n","\n","# Se usa datagen.flow() para aumentar los datos\n","train_generator = datagen.flow(X_train, y_train, batch_size=64)\n","\n","# Compilación del modelo\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","# Entrenar el modelo\n","history = model.fit(train_generator,  # Datos de entrenamiento\n","                    epochs=100,  # Número máximo de épocas\n","                    batch_size=32,  # Tamaño del lote\n","                    validation_data=(X_val, y_val),  # Datos de validación\n","                    callbacks=[early_stopping])  # Callback de early stopping"],"metadata":{"id":"ZEetL_XJqlKy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Evaluacion del modelo"],"metadata":{"id":"7gDQ386Kqpt-"}},{"cell_type":"code","source":["basic_model_eval = model.evaluate(X_test, y_test)\n","print(f\"Modelo básico: error y accuracy {basic_model_eval}\")"],"metadata":{"id":"24lWU04JqqKB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Guardar modelo"],"metadata":{"id":"Sh48PpgequWG"}},{"cell_type":"code","source":["# Guardar el modelo\n","#model.save('modelConvo_1.keras')  # Mejor usar el formato .keras en lugar de .h5\n","\n","# Cargar el modelo\n","#from tensorflow.keras.models import load_model\n","#model = load_model('modelConvo_1.keras')"],"metadata":{"id":"E8mwNXNQqvz3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Evaluacion grafica"],"metadata":{"id":"jTIIWR3sqyca"}},{"cell_type":"code","source":["# Importar las librerías necesarias\n","import matplotlib.pyplot as plt  # Para graficar\n","import tensorflow as tf          # Para manejar el historial del entrenamiento\n","\n","# Acceder a la precisión de entrenamiento y validación desde el historial\n","train_accuracy = history.history['accuracy']    # Precisión de entrenamiento\n","val_accuracy = history.history['val_accuracy']  # Precisión de validación\n","\n","# Acceder a la pérdida de entrenamiento y validación desde el historial\n","train_loss = history.history['loss']         # Pérdida de entrenamiento\n","val_loss = history.history['val_loss']       # Pérdida de validación\n","\n","# Configuración de la figura con 1 fila y 2 columnas\n","fig, axs = plt.subplots(1, 2, figsize=(16, 6))  # Ajusta el tamaño según lo necesites\n","\n","# Graficar precisión de entrenamiento y validación\n","axs[0].plot(train_accuracy, label='Entrenamiento', color=\"blue\")    # Precisión de entrenamiento\n","axs[0].plot(val_accuracy, label='Validación', color=\"red\")          # Precisión de validación\n","axs[0].set_title('Accuracy de entrenamiento por epoch')  # Título del gráfico\n","axs[0].set_xlabel('Epoch')                               # Etiqueta del eje X\n","axs[0].set_ylabel('Precisión')                           # Etiqueta del eje Y\n","axs[0].set_ylim(0, 1)\n","axs[0].legend()                                          # Mostrar la leyenda\n","axs[0].grid(True)                                        # Activar la cuadrícula\n","\n","# Graficar pérdida de entrenamiento y validación\n","axs[1].plot(train_loss, label='Entrenamiento', color=\"blue\")    # Pérdida de entrenamiento\n","axs[1].plot(val_loss, label='Validación', color=\"red\")          # Pérdida de validación\n","axs[1].set_title('Error de entrenamiento por epoch')   # Título del gráfico\n","axs[1].set_xlabel('Epoch')                             # Etiqueta del eje X\n","axs[1].set_ylabel('Error')                             # Etiqueta del eje Y\n","axs[1].legend()                                        # Mostrar la leyenda\n","axs[1].grid(True)                                      # Activar la cuadrícula\n","\n","plt.tight_layout()                                     # Ajustar el diseño para evitar solapamientos\n","plt.show()                                             # Mostrar los gráficos"],"metadata":{"id":"8tspZcnQqy3_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Matriz de confucion"],"metadata":{"id":"wgRdd9Mqq3LM"}},{"cell_type":"code","source":["# Importar las librerías necesarias\n","import numpy as np                         # Para operaciones numéricas y manipulación de arrays\n","from sklearn.metrics import confusion_matrix  # Para generar la matriz de confusión\n","import seaborn as sns                      # Para visualizar la matriz de confusión\n","import matplotlib.pyplot as plt            # Para visualización de gráficos\n","\n","# Calcular las clasificaciones reales y predichas\n","reales = np.argmax(y_test, axis=1)  # Clasificaciones reales de las imágenes\n","predichos = np.argmax(model.predict(X_test), axis=1)  # Predicciones del modelo\n","num_clases = len(data.class_names)  # Número de clases (asegúrate de que coincida)\n","\n","# Generar la matriz de confusión\n","conf_matrix = confusion_matrix(reales, predichos)\n","\n","# Graficar la matriz de confusión usando seaborn\n","plt.figure(figsize=(12, 12))\n","sns.heatmap(\n","    conf_matrix,\n","    annot=False,                     # No anotar los valores en la matriz\n","    fmt='d',                         # Formato de anotación\n","    cmap='Blues',                    # Colormap para la visualización\n","    xticklabels=data.class_names,    # Etiquetas para el eje X\n","    yticklabels=data.class_names     # Etiquetas para el eje Y\n",")\n","\n","# Etiquetas y título\n","plt.xlabel('Predicho')              # Etiqueta del eje X\n","plt.ylabel('Real')                  # Etiqueta del eje Y\n","plt.title('Matriz de confusión')    # Título de la gráfica\n","plt.show()"],"metadata":{"id":"96ejV2sCq3nZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Prueba de clasificaciones"],"metadata":{"id":"2GF9EYTaq-Ik"}},{"cell_type":"code","source":["# Importar las librerías necesarias\n","import numpy as np           # Para operaciones numéricas y manipulación de arrays\n","import matplotlib.pyplot as plt  # Para visualización de imágenes\n","\n","# Mostrar 10 imágenes con sus clasificaciones reales y predichas\n","n = 10  # Número de imágenes a mostrar\n","fig, ax = plt.subplots(1, n, figsize=(15, 15))  # Ajustamos el tamaño del gráfico\n","\n","for i in range(n):\n","    # Obtener la clasificación real y la predicción del modelo\n","    real = np.argmax(y_test[i])  # Clasificación real de la imagen\n","\n","    # Como las imágenes no están aplanadas, no hacemos reshape\n","    img = X_test[i]  # Tomamos la imagen directamente\n","\n","    # Realizar la predicción del modelo\n","    prediction = model.predict(img.reshape(1, img.shape[0], img.shape[1], img.shape[2]))  # Predicción del modelo\n","    prediction = np.argmax(prediction)  # Obtener el índice de la clase predicha\n","\n","    # Mostrar la imagen\n","    ax[i].imshow(img)  # Mostrar la imagen en su forma original\n","    ax[i].axis(\"off\")  # Ocultar los ejes\n","    ax[i].set_title(f\"Real: {data.class_names[real]}, \\nClasificado: {data.class_names[prediction]}\", fontsize=7)  # Título\n","\n","plt.show()  # Mostrar la figura con las imágenes"],"metadata":{"id":"xFW0d8exq-s9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* SHAP"],"metadata":{"id":"ztwC0quZrEpY"}},{"cell_type":"code","source":["import numpy as np\n","import shap\n","import matplotlib.pyplot as plt\n","\n","# Supongamos que X_test es tu conjunto de datos de prueba y y_test son las etiquetas correspondientes.\n","\n","# Step 1: Define a function that returns the model's predictions for all classes\n","def f(x):\n","    return model(x)\n","\n","# Step 2: Create a masker for the images\n","masker_blur = shap.maskers.Image(\"blur(32,32)\", X_test[0].shape)\n","\n","# Step 3: Create an Explainer object\n","explainer = shap.Explainer(f, masker_blur, output_names=[f\"Clase {i}\" for i in range(20)])\n","\n","# Step 4: Loop over a subset of images for SHAP explanation\n","for ind in range(min(5, len(X_test))):  # Cambia 5 por el número de ejemplos que quieras visualizar\n","    shap_values_ = explainer(X_test[[ind]], max_evals=5000, batch_size=50)\n","\n","    # Get the class probabilities from the model\n","    class_probs = model.predict(X_test[[ind]])[0]\n","    rounded_probs = np.round(class_probs, 2)  # Redondear las probabilidades a dos decimales\n","\n","    # Print the predicted probabilities for each class\n","    print(f\"Probabilidades para la imagen {ind}:\")\n","    for i in range(len(rounded_probs)):\n","        print(f\"Clase {i}: {rounded_probs[i]:.2f}\")  # Asegurarse de imprimir con dos decimales\n","\n","    # Plot SHAP values\n","    shap.image_plot(shap_values_, labels=[f\"Clase {i}\" for i in range(20)], show=False)\n","\n","    # Set title for the plot with the actual class\n","    plt.title(f\"Clase real: {np.argmax(y_test[[ind]][0])}\", fontsize=14)\n","    plt.show()\n"],"metadata":{"id":"ZpyU2yNQrGos"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Metricas de precision"],"metadata":{"id":"cRMLwR7LrT0F"}},{"cell_type":"code","source":["from sklearn.metrics import recall_score, f1_score\n","\n","# Calcular las clasificaciones reales y predichas\n","reales = np.argmax(y_test, axis=1)  # Clasificaciones reales de las imágenes\n","predichos = np.argmax(model.predict(X_test), axis=1)  # Predicciones del modelo\n","\n","# Calcular recall y F1 score de forma micro y macro\n","recall_micro = recall_score(reales, predichos, average='micro')\n","f1_micro = f1_score(reales, predichos, average='micro')\n","\n","recall_macro = recall_score(reales, predichos, average='macro')\n","f1_macro = f1_score(reales, predichos, average='macro')\n","\n","# Mostrar los resultados\n","print(f\"Recall Micro: {recall_micro:.4f}\")\n","print(f\"F1 Score Micro: {f1_micro:.4f}\")\n","print(f\"Recall Macro: {recall_macro:.4f}\")\n","print(f\"F1 Score Macro: {f1_macro:.4f}\")"],"metadata":{"id":"wiriPYrSrVUA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Modelo preentrenado"],"metadata":{"id":"7vNZ9CeJrcSN"}},{"cell_type":"markdown","source":["* Carga de datos"],"metadata":{"id":"WMK31Kfhrkxs"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","\n","# Especificar el directorio que contiene las imágenes\n","#directory = \"/content/drive/MyDrive/Ciencia de datos/Proyecto/vehicle_data\"\n","directory = \"C:/Users/cesar/OneDrive/Escritorio/vehicle_data\"\n","\n","# Cargar los datos como root_directory\n","data = keras.utils.image_dataset_from_directory(\n","    directory,               # Directorio que contiene las imágenes\n","    labels=\"inferred\",       # Inferir las etiquetas de los nombres de las carpetas\n","    label_mode=\"int\",        # Usar enteros como modo de etiquetas\n","    color_mode=\"rgb\",        # Cargar imágenes en modo RGB\n","    batch_size=6,            # Tamaño del lote\n","    shuffle=True,            # Aleatorizar los datos\n","    seed=1234                # Semilla para la aleatorización\n",")"],"metadata":{"id":"M3QMvmgorine"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Transformaciones"],"metadata":{"id":"8VedHE7MrnKY"}},{"cell_type":"code","source":["# Importar las librerías necesarias\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","# Convertir datos a numpy arrays\n","# (esto puede variar dependiendo de cómo cargaste los datos)\n","images, labels = [], []  # Listas para almacenar imágenes y etiquetas\n","\n","# Recorrer los lotes de datos y agregar a las listas\n","for image_batch, label_batch in data:\n","    images.extend(image_batch.numpy())  # Convertir y agregar imágenes\n","    labels.extend(label_batch.numpy())   # Convertir y agregar etiquetas\n","\n","# Convertir listas a arrays de numpy\n","images = np.array(images)\n","labels = np.array(labels)\n","\n","# Estratificación y división de datos\n","# X contendrá las imágenes y y contendrá las etiquetas\n","X_train, X_test, y_train, y_test = train_test_split(\n","    images, labels, test_size=0.3, random_state=42, stratify=labels\n",")\n","\n","# Dividir el conjunto de prueba en validación y prueba\n","X_val, X_test, y_val, y_test = train_test_split(\n","    X_test, y_test, test_size=0.5, random_state=42, stratify=y_test\n",")\n","\n","k=20\n","# Mostrar la cantidad de datos en cada conjunto\n","print(len(y_train), len(y_val), len(y_test))\n","\n","# Normalizar los píxeles entre 0 y 1\n","X_train = X_train.astype('float32') / 255.0\n","X_val = X_val.astype('float32') / 255.0\n","X_test = X_test.astype('float32') / 255.0\n","\n","# Codificación one-hot para las etiquetas\n","num_classes = len(data.class_names)  # Número de clases\n","y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n","y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n","y_test = tf.keras.utils.to_categorical(y_test, num_classes)"],"metadata":{"id":"rO7M62Z8ro8Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Modelo y entrenamiento"],"metadata":{"id":"zuTCwFx-rsWk"}},{"cell_type":"code","source":["from tensorflow.keras.applications import ResNet50  # Importa el modelo ResNet50 preentrenado\n","from tensorflow.keras.models import Model  # Importa la clase Model para crear un modelo personalizado\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D  # Importa capas Dense y GlobalAveragePooling2D\n","\n","# Pre-entrenado ResNet50\n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))  # Carga ResNet50\n","\n","# Capas personalizadas para clasificación\n","x = base_model.output  # Obtiene la salida del modelo base\n","x = GlobalAveragePooling2D()(x)  # Aplica un Pooling global para reducir dimensionalidad\n","x = Dense(256, activation='relu')(x)  # Añade una capa densa de 256 neuronas con activación ReLU\n","predictions = Dense(k, activation='softmax')(x)  # Crea la capa de salida con activación softmax para k clases\n","model = Model(inputs=base_model.input, outputs=predictions)  # Define el modelo combinando el modelo base y las capas añadidas\n","\n","for layer in base_model.layers:\n","    layer.trainable = False  # Desactiva el entrenamiento de las capas del modelo base\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Compila el modelo con optimizador Adam y entropía cruzada categórica"],"metadata":{"id":"9d02iz9lrtyf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Entrenar modelo"],"metadata":{"id":"j7c_OXdwrzDh"}},{"cell_type":"code","source":["history = model.fit(X_train,y_train, epochs=40, batch_size=64, validation_data=(X_val, y_val))"],"metadata":{"id":"sFyRnmx3r0aH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Evaluacion del modelo"],"metadata":{"id":"RmurFfQdr6iF"}},{"cell_type":"code","source":["basic_model_eval = model.evaluate(X_test, y_test)\n","print(f\"Modelo básico: error y accuracy {basic_model_eval}\")"],"metadata":{"id":"yxAaQmL5r8ap"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Guardar modelo"],"metadata":{"id":"-hOWAEovr-3E"}},{"cell_type":"code","source":["# Guardar modelo\n","#model.save('model_preentrenado.h5')\n","# Volver a cargar en el ambiente un modelo guardado\n","#from tensorflow.keras.models import load_model\n","#model = load_model('model_preentrenado.h5')"],"metadata":{"id":"3fdenuPVsDaY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Graficacion"],"metadata":{"id":"tde4u1EusG8H"}},{"cell_type":"code","source":["# Importar las librerías necesarias\n","import matplotlib.pyplot as plt  # Para graficar\n","import tensorflow as tf          # Para manejar el historial del entrenamiento\n","\n","# Acceder a la precisión de entrenamiento y validación desde el historial\n","train_accuracy = history.history['accuracy']    # Precisión de entrenamiento\n","val_accuracy = history.history['val_accuracy']  # Precisión de validación\n","\n","# Acceder a la pérdida de entrenamiento y validación desde el historial\n","train_loss = history.history['loss']         # Pérdida de entrenamiento\n","val_loss = history.history['val_loss']       # Pérdida de validación\n","\n","# Configuración de la figura con 1 fila y 2 columnas\n","fig, axs = plt.subplots(1, 2, figsize=(16, 6))  # Ajusta el tamaño según lo necesites\n","\n","# Graficar precisión de entrenamiento y validación\n","axs[0].plot(train_accuracy, label='Entrenamiento', color=\"blue\")    # Precisión de entrenamiento\n","axs[0].plot(val_accuracy, label='Validación', color=\"red\")          # Precisión de validación\n","axs[0].set_title('Accuracy de entrenamiento por epoch')  # Título del gráfico\n","axs[0].set_xlabel('Epoch')                               # Etiqueta del eje X\n","axs[0].set_ylabel('Precisión')                           # Etiqueta del eje Y\n","axs[0].set_ylim(0, 1)\n","axs[0].legend()                                          # Mostrar la leyenda\n","axs[0].grid(True)                                        # Activar la cuadrícula\n","\n","# Graficar pérdida de entrenamiento y validación\n","axs[1].plot(train_loss, label='Entrenamiento', color=\"blue\")    # Pérdida de entrenamiento\n","axs[1].plot(val_loss, label='Validación', color=\"red\")          # Pérdida de validación\n","axs[1].set_title('Error de entrenamiento por epoch')   # Título del gráfico\n","axs[1].set_xlabel('Epoch')                             # Etiqueta del eje X\n","axs[1].set_ylabel('Error')                             # Etiqueta del eje Y\n","axs[1].legend()                                        # Mostrar la leyenda\n","axs[1].grid(True)                                      # Activar la cuadrícula\n","\n","plt.tight_layout()                                     # Ajustar el diseño para evitar solapamientos\n","plt.show()                                             # Mostrar los gráficos"],"metadata":{"id":"nvBOcOjEsHgZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Matriz de confucion"],"metadata":{"id":"jQsWlxZ0sLyA"}},{"cell_type":"code","source":["# Importar las librerías necesarias\n","import numpy as np                         # Para operaciones numéricas y manipulación de arrays\n","from sklearn.metrics import confusion_matrix  # Para generar la matriz de confusión\n","import seaborn as sns                      # Para visualizar la matriz de confusión\n","import matplotlib.pyplot as plt            # Para visualización de gráficos\n","\n","# Calcular las clasificaciones reales y predichas\n","reales = np.argmax(y_test, axis=1)  # Clasificaciones reales de las imágenes\n","predichos = np.argmax(model.predict(X_test), axis=1)  # Predicciones del modelo\n","num_clases = len(data.class_names)  # Número de clases (asegúrate de que coincida)\n","\n","# Generar la matriz de confusión\n","conf_matrix = confusion_matrix(reales, predichos)\n","\n","# Graficar la matriz de confusión usando seaborn\n","plt.figure(figsize=(12, 12))\n","sns.heatmap(\n","    conf_matrix,\n","    annot=False,                     # No anotar los valores en la matriz\n","    fmt='d',                         # Formato de anotación\n","    cmap='Blues',                    # Colormap para la visualización\n","    xticklabels=data.class_names,    # Etiquetas para el eje X\n","    yticklabels=data.class_names     # Etiquetas para el eje Y\n",")\n","\n","# Etiquetas y título\n","plt.xlabel('Predicho')              # Etiqueta del eje X\n","plt.ylabel('Real')                  # Etiqueta del eje Y\n","plt.title('Matriz de confusión')    # Título de la gráfica\n","plt.show()"],"metadata":{"id":"JkSMtw12sMPD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Prueba de clasificaciones"],"metadata":{"id":"fNP-nN33sQss"}},{"cell_type":"code","source":["# Importar las librerías necesarias\n","import numpy as np           # Para operaciones numéricas y manipulación de arrays\n","import matplotlib.pyplot as plt  # Para visualización de imágenes\n","\n","# Mostrar 10 imágenes con sus clasificaciones reales y predichas\n","n = 10  # Número de imágenes a mostrar\n","fig, ax = plt.subplots(1, n, figsize=(15, 15))  # Ajustamos el tamaño del gráfico\n","\n","for i in range(n):\n","    # Obtener la clasificación real y la predicción del modelo\n","    real = np.argmax(y_test[i])  # Clasificación real de la imagen\n","\n","    # Como las imágenes no están aplanadas, no hacemos reshape\n","    img = X_test[i]  # Tomamos la imagen directamente\n","\n","    # Realizar la predicción del modelo\n","    prediction = model.predict(img.reshape(1, img.shape[0], img.shape[1], img.shape[2]))  # Predicción del modelo\n","    prediction = np.argmax(prediction)  # Obtener el índice de la clase predicha\n","\n","    # Mostrar la imagen\n","    ax[i].imshow(img)  # Mostrar la imagen en su forma original\n","    ax[i].axis(\"off\")  # Ocultar los ejes\n","    ax[i].set_title(f\"Real: {data.class_names[real]}, \\nClasificado: {data.class_names[prediction]}\", fontsize=7)  # Título\n","\n","plt.show()  # Mostrar la figura con las imágenes"],"metadata":{"id":"ljzx28AZsRMY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Metricas"],"metadata":{"id":"8g7S0ZrusU-A"}},{"cell_type":"code","source":["from sklearn.metrics import recall_score, f1_score\n","\n","# Calcular las clasificaciones reales y predichas\n","reales = np.argmax(y_test, axis=1)  # Clasificaciones reales de las imágenes\n","predichos = np.argmax(model.predict(X_test), axis=1)  # Predicciones del modelo\n","\n","# Calcular recall y F1 score de forma micro y macro\n","recall_micro = recall_score(reales, predichos, average='micro')\n","f1_micro = f1_score(reales, predichos, average='micro')\n","\n","recall_macro = recall_score(reales, predichos, average='macro')\n","f1_macro = f1_score(reales, predichos, average='macro')\n","\n","# Mostrar los resultados\n","print(f\"Recall Micro: {recall_micro:.4f}\")\n","print(f\"F1 Score Micro: {f1_micro:.4f}\")\n","print(f\"Recall Macro: {recall_macro:.4f}\")\n","print(f\"F1 Score Macro: {f1_macro:.4f}\")"],"metadata":{"id":"bXGbKtAysVbf"},"execution_count":null,"outputs":[]}]}